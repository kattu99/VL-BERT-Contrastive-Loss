2020-11-17 12:51:55,524 training args:Namespace(cfg='./cfgs/vqa/base_4x16G_fp32.yaml', cudnn_off=False, dist=False, do_test=False, log_dir='./checkpoints/output/vl-bert/vqa/base_4x16G_fp32/train2014+val2014_train/tensorboard_logs', model_dir='', partial_pretrain=None, slurm=False)

2020-11-17 12:51:55,529 training config:{'CHECKPOINT_FREQUENT': 1,
 'DATASET': {'ADD_IMAGE_AS_A_BOX': True,
             'ANSWER_VOCAB_FILE': './data/coco/vqa/answers_vqa.txt',
             'ANSWER_VOCAB_SIZE': 3129,
             'APPEND_INDEX': False,
             'BASIC_ALIGN': False,
             'BOXES': '10-100ada',
             'CACHE_MODE': False,
             'DATASET': 'vqa',
             'DATASET_PATH': './data/coco',
             'IGNORE_DB_CACHE': False,
             'LABEL_INDEX_IN_BATCH': -1,
             'MASK_SIZE': 14,
             'ONLY_USE_RELEVANT_DETS': True,
             'QA2R_AUG': False,
             'QA2R_NOQ': False,
             'ROOT_PATH': './',
             'TASK': 'Q2AR',
             'TEST_ANNOTATION_FILE': '',
             'TEST_IMAGE_SET': 'test2015',
             'TRAIN_ANNOTATION_FILE': '',
             'TRAIN_IMAGE_SET': 'train2014+val2014',
             'USE_IMDB': False,
             'VAL_ANNOTATION_FILE': '',
             'VAL_IMAGE_SET': 'val2014',
             'ZIP_MODE': False},
 'GPUS': '0',
 'LOG_FREQUENT': 100,
 'MODEL_PREFIX': 'vl-bert_base_res101_vqa',
 'MODULE': 'ResNetVLBERT',
 'NETWORK': {'ANS_LOSS_TYPE': 'bce',
             'ANS_LOSS_WEIGHT': 1.0,
             'BERT_ALIGN_ANSWER': True,
             'BERT_ALIGN_QUESTION': True,
             'BERT_FROZEN': False,
             'BERT_MODEL_NAME': './model/pretrained_model/bert-base-uncased',
             'BERT_PRETRAINED': '',
             'BERT_PRETRAINED_EPOCH': 0,
             'BERT_USE_LAYER': -2,
             'BERT_WITH_MLM_LOSS': False,
             'BERT_WITH_NSP_LOSS': False,
             'BLIND': False,
             'CLASSIFIER_DROPOUT': 0.1,
             'CLASSIFIER_HIDDEN_SIZE': 1024,
             'CLASSIFIER_PRETRAINED': True,
             'CLASSIFIER_SIGMOID': False,
             'CLASSIFIER_SIGMOID_LOSS_POSITIVE_WEIGHT': 1.0,
             'CLASSIFIER_TYPE': 'mlm',
             'CNN_LOSS_WEIGHT': 1.0,
             'ENABLE_CNN_REG_LOSS': False,
             'FOR_MASK_VL_MODELING_PRETRAIN': False,
             'IMAGE_C5_DILATED': True,
             'IMAGE_FEAT_PRECOMPUTED': True,
             'IMAGE_FINAL_DIM': 768,
             'IMAGE_FROZEN_BACKBONE_STAGES': [1, 2],
             'IMAGE_FROZEN_BN': True,
             'IMAGE_NUM_LAYERS': 101,
             'IMAGE_PRETRAINED': '',
             'IMAGE_PRETRAINED_EPOCH': 0,
             'IMAGE_SEMANTIC': False,
             'IMAGE_STRIDE_IN_1x1': True,
             'NO_GROUNDING': False,
             'NO_OBJ_ATTENTION': False,
             'OUTPUT_CONV5': False,
             'PARTIAL_PRETRAIN': './model/pretrained_model/vl-bert-base-e2e.model',
             'PARTIAL_PRETRAIN_PREFIX_CHANGES': ['vlbert.mlm_head.predictions.transform->final_mlp.0',
                                                 'module.vlbert.mlm_head.predictions.transform->module.final_mlp.0',
                                                 'vlbert->vlbert',
                                                 'module.vlbert->module.vlbert'],
             'PIXEL_MEANS': [102.9801, 115.9465, 122.7717],
             'PIXEL_STDS': [1.0, 1.0, 1.0],
             'REPLACE_OBJECT_CHANGE_LABEL': True,
             'VLBERT': {'attention_probs_dropout_prob': 0.1,
                        'hidden_act': 'gelu',
                        'hidden_dropout_prob': 0.1,
                        'hidden_size': 768,
                        'initializer_range': 0.02,
                        'input_size': 1280,
                        'input_transform_type': 1,
                        'intermediate_size': 3072,
                        'max_position_embeddings': 512,
                        'num_attention_heads': 12,
                        'num_hidden_layers': 12,
                        'obj_pos_id_relative': True,
                        'object_word_embed_mode': 2,
                        'position_padding_idx': -1,
                        'type_vocab_size': 3,
                        'visual_ln': True,
                        'visual_scale_object_init': 0.0,
                        'visual_scale_text_init': 0.0,
                        'visual_size': 768,
                        'vocab_size': 30522,
                        'with_pooler': False,
                        'word_embedding_frozen': False}},
 'NUM_WORKERS_PER_GPU': 4,
 'OUTPUT_PATH': './checkpoints/output/vl-bert/vqa/',
 'RNG_SEED': 12345,
 'SCALES': [600, 1000],
 'TEST': {'BATCH_IMAGES': 64,
          'FLIP_PROB': 0,
          'SHUFFLE': False,
          'TEST_EPOCH': 0},
 'TRAIN': {'ASPECT_GROUPING': False,
           'AUTO_RESUME': True,
           'BATCH_IMAGES': 32,
           'BEGIN_EPOCH': 3,
           'CLIP_GRAD_NORM': 1.0,
           'END_EPOCH': 5,
           'FLIP_PROB': 0.5,
           'FP16': False,
           'FP16_LOSS_SCALE': 128.0,
           'GRAD_ACCUMULATE_STEPS': 1,
           'LOSS_LOGGERS': [('ans_loss', 'AnsLoss')],
           'LR': 6.25e-07,
           'LR_FACTOR': 0.1,
           'LR_MULT': [],
           'LR_SCHEDULE': 'triangle',
           'LR_STEP': [],
           'MOMENTUM': 0.9,
           'OPTIMIZER': 'AdamW',
           'RESUME': True,
           'SHUFFLE': True,
           'VISUAL_SCALE_CLIP_GRAD_NORM': -1,
           'VISUAL_SCALE_OBJECT_LR_MULT': 1.0,
           'VISUAL_SCALE_TEXT_LR_MULT': 1.0,
           'WARMUP': True,
           'WARMUP_FACTOR': 0.0,
           'WARMUP_METHOD': 'linear',
           'WARMUP_STEPS': 500,
           'WD': 0.0001},
 'VAL': {'BATCH_IMAGES': 64, 'FLIP_PROB': 0, 'SHUFFLE': False},
 'VAL_FREQUENT': 1}

2020-11-17 12:51:56,057 loading vocabulary file ./model/pretrained_model/bert-base-uncased/vocab.txt
2020-11-17 12:52:04,759 >> Trainable Parameters:
2020-11-17 12:52:04,761 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,761 |Name                                                         |Dtype            |Shape           |#Params     |
2020-11-17 12:52:04,761 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,761 |image_feature_extractor.obj_downsample.1.weight              |torch.float32    |(768, 4096)     |3145728     |
2020-11-17 12:52:04,761 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,761 |image_feature_extractor.obj_downsample.1.bias                |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,761 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,761 |object_linguistic_embeddings.weight                          |torch.float32    |(1, 768)        |768         |
2020-11-17 12:52:04,761 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,761 |vlbert.word_embeddings.weight                                |torch.float32    |(30522, 768)    |23440896    |
2020-11-17 12:52:04,762 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,762 |vlbert.end_embedding.weight                                  |torch.float32    |(1, 768)        |768         |
2020-11-17 12:52:04,762 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,762 |vlbert.position_embeddings.weight                            |torch.float32    |(512, 768)      |393216      |
2020-11-17 12:52:04,762 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,762 |vlbert.token_type_embeddings.weight                          |torch.float32    |(3, 768)        |2304        |
2020-11-17 12:52:04,762 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,762 |vlbert.embedding_LayerNorm.weight                            |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,762 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,762 |vlbert.embedding_LayerNorm.bias                              |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,762 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,762 |vlbert.visual_ln_text.weight                                 |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,762 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,762 |vlbert.visual_ln_text.bias                                   |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,763 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,763 |vlbert.visual_ln_object.weight                               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,763 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,763 |vlbert.visual_ln_object.bias                                 |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,763 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,763 |vlbert.encoder.layer.0.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,763 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,763 |vlbert.encoder.layer.0.attention.self.query.bias             |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,763 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,763 |vlbert.encoder.layer.0.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,763 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,763 |vlbert.encoder.layer.0.attention.self.key.bias               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,763 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,763 |vlbert.encoder.layer.0.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,763 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,764 |vlbert.encoder.layer.0.attention.self.value.bias             |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,764 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,764 |vlbert.encoder.layer.0.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,764 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,764 |vlbert.encoder.layer.0.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,764 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,764 |vlbert.encoder.layer.0.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,764 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,764 |vlbert.encoder.layer.0.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,764 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,764 |vlbert.encoder.layer.0.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
2020-11-17 12:52:04,764 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,764 |vlbert.encoder.layer.0.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
2020-11-17 12:52:04,764 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,764 |vlbert.encoder.layer.0.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
2020-11-17 12:52:04,764 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,765 |vlbert.encoder.layer.0.output.dense.bias                     |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,765 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,765 |vlbert.encoder.layer.0.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,765 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,765 |vlbert.encoder.layer.0.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,765 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,765 |vlbert.encoder.layer.1.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,765 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,765 |vlbert.encoder.layer.1.attention.self.query.bias             |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,765 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,765 |vlbert.encoder.layer.1.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,765 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,765 |vlbert.encoder.layer.1.attention.self.key.bias               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,765 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,765 |vlbert.encoder.layer.1.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,766 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,766 |vlbert.encoder.layer.1.attention.self.value.bias             |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,766 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,766 |vlbert.encoder.layer.1.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,766 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,766 |vlbert.encoder.layer.1.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,766 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,766 |vlbert.encoder.layer.1.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,766 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,766 |vlbert.encoder.layer.1.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,766 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,766 |vlbert.encoder.layer.1.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
2020-11-17 12:52:04,766 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,766 |vlbert.encoder.layer.1.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
2020-11-17 12:52:04,766 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,766 |vlbert.encoder.layer.1.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
2020-11-17 12:52:04,767 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,767 |vlbert.encoder.layer.1.output.dense.bias                     |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,767 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,767 |vlbert.encoder.layer.1.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,767 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,767 |vlbert.encoder.layer.1.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,767 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,767 |vlbert.encoder.layer.2.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,767 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,767 |vlbert.encoder.layer.2.attention.self.query.bias             |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,767 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,767 |vlbert.encoder.layer.2.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,767 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,767 |vlbert.encoder.layer.2.attention.self.key.bias               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,767 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,767 |vlbert.encoder.layer.2.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,767 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,768 |vlbert.encoder.layer.2.attention.self.value.bias             |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,768 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,768 |vlbert.encoder.layer.2.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,768 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,768 |vlbert.encoder.layer.2.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,768 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,768 |vlbert.encoder.layer.2.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,768 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,768 |vlbert.encoder.layer.2.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,768 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,768 |vlbert.encoder.layer.2.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
2020-11-17 12:52:04,768 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,768 |vlbert.encoder.layer.2.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
2020-11-17 12:52:04,768 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,768 |vlbert.encoder.layer.2.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
2020-11-17 12:52:04,769 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,769 |vlbert.encoder.layer.2.output.dense.bias                     |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,769 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,769 |vlbert.encoder.layer.2.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,769 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,769 |vlbert.encoder.layer.2.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,769 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,769 |vlbert.encoder.layer.3.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,769 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,769 |vlbert.encoder.layer.3.attention.self.query.bias             |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,769 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,769 |vlbert.encoder.layer.3.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,769 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,769 |vlbert.encoder.layer.3.attention.self.key.bias               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,769 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,769 |vlbert.encoder.layer.3.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,770 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,770 |vlbert.encoder.layer.3.attention.self.value.bias             |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,770 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,770 |vlbert.encoder.layer.3.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,770 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,770 |vlbert.encoder.layer.3.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,770 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,770 |vlbert.encoder.layer.3.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,770 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,770 |vlbert.encoder.layer.3.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,770 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,770 |vlbert.encoder.layer.3.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
2020-11-17 12:52:04,770 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,770 |vlbert.encoder.layer.3.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
2020-11-17 12:52:04,770 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,770 |vlbert.encoder.layer.3.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
2020-11-17 12:52:04,771 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,771 |vlbert.encoder.layer.3.output.dense.bias                     |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,771 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,771 |vlbert.encoder.layer.3.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,771 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,771 |vlbert.encoder.layer.3.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,771 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,771 |vlbert.encoder.layer.4.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,771 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,771 |vlbert.encoder.layer.4.attention.self.query.bias             |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,771 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,771 |vlbert.encoder.layer.4.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,771 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,771 |vlbert.encoder.layer.4.attention.self.key.bias               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,771 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,772 |vlbert.encoder.layer.4.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,772 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,772 |vlbert.encoder.layer.4.attention.self.value.bias             |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,772 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,772 |vlbert.encoder.layer.4.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,772 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,772 |vlbert.encoder.layer.4.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,772 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,772 |vlbert.encoder.layer.4.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,772 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,772 |vlbert.encoder.layer.4.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,772 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,772 |vlbert.encoder.layer.4.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
2020-11-17 12:52:04,772 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,772 |vlbert.encoder.layer.4.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
2020-11-17 12:52:04,773 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,773 |vlbert.encoder.layer.4.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
2020-11-17 12:52:04,773 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,773 |vlbert.encoder.layer.4.output.dense.bias                     |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,773 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,773 |vlbert.encoder.layer.4.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,773 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,773 |vlbert.encoder.layer.4.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,773 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,773 |vlbert.encoder.layer.5.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,773 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,773 |vlbert.encoder.layer.5.attention.self.query.bias             |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,773 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,773 |vlbert.encoder.layer.5.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,773 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,773 |vlbert.encoder.layer.5.attention.self.key.bias               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,774 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,774 |vlbert.encoder.layer.5.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,774 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,774 |vlbert.encoder.layer.5.attention.self.value.bias             |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,774 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,774 |vlbert.encoder.layer.5.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,774 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,774 |vlbert.encoder.layer.5.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,774 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,774 |vlbert.encoder.layer.5.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,774 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,774 |vlbert.encoder.layer.5.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,774 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,774 |vlbert.encoder.layer.5.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
2020-11-17 12:52:04,774 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,775 |vlbert.encoder.layer.5.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
2020-11-17 12:52:04,775 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,775 |vlbert.encoder.layer.5.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
2020-11-17 12:52:04,775 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,775 |vlbert.encoder.layer.5.output.dense.bias                     |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,775 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,775 |vlbert.encoder.layer.5.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,775 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,775 |vlbert.encoder.layer.5.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,775 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,775 |vlbert.encoder.layer.6.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,775 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,775 |vlbert.encoder.layer.6.attention.self.query.bias             |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,775 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,775 |vlbert.encoder.layer.6.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,776 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,776 |vlbert.encoder.layer.6.attention.self.key.bias               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,776 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,776 |vlbert.encoder.layer.6.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,776 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,776 |vlbert.encoder.layer.6.attention.self.value.bias             |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,776 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,776 |vlbert.encoder.layer.6.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,776 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,776 |vlbert.encoder.layer.6.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,776 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,776 |vlbert.encoder.layer.6.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,776 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,776 |vlbert.encoder.layer.6.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,776 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,776 |vlbert.encoder.layer.6.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
2020-11-17 12:52:04,776 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,777 |vlbert.encoder.layer.6.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
2020-11-17 12:52:04,777 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,777 |vlbert.encoder.layer.6.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
2020-11-17 12:52:04,777 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,777 |vlbert.encoder.layer.6.output.dense.bias                     |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,777 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,777 |vlbert.encoder.layer.6.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,777 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,777 |vlbert.encoder.layer.6.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,777 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,777 |vlbert.encoder.layer.7.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,777 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,777 |vlbert.encoder.layer.7.attention.self.query.bias             |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,777 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,777 |vlbert.encoder.layer.7.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,778 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,778 |vlbert.encoder.layer.7.attention.self.key.bias               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,778 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,778 |vlbert.encoder.layer.7.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,778 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,778 |vlbert.encoder.layer.7.attention.self.value.bias             |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,778 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,778 |vlbert.encoder.layer.7.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,778 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,778 |vlbert.encoder.layer.7.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,778 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,778 |vlbert.encoder.layer.7.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,778 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,778 |vlbert.encoder.layer.7.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,778 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,779 |vlbert.encoder.layer.7.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
2020-11-17 12:52:04,779 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,779 |vlbert.encoder.layer.7.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
2020-11-17 12:52:04,779 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,779 |vlbert.encoder.layer.7.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
2020-11-17 12:52:04,779 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,779 |vlbert.encoder.layer.7.output.dense.bias                     |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,779 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,779 |vlbert.encoder.layer.7.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,779 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,779 |vlbert.encoder.layer.7.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,779 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,779 |vlbert.encoder.layer.8.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,779 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,779 |vlbert.encoder.layer.8.attention.self.query.bias             |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,779 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,780 |vlbert.encoder.layer.8.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,780 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,780 |vlbert.encoder.layer.8.attention.self.key.bias               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,780 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,780 |vlbert.encoder.layer.8.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,780 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,780 |vlbert.encoder.layer.8.attention.self.value.bias             |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,780 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,780 |vlbert.encoder.layer.8.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,780 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,780 |vlbert.encoder.layer.8.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,780 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,780 |vlbert.encoder.layer.8.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,780 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,780 |vlbert.encoder.layer.8.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,781 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,781 |vlbert.encoder.layer.8.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
2020-11-17 12:52:04,781 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,781 |vlbert.encoder.layer.8.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
2020-11-17 12:52:04,781 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,781 |vlbert.encoder.layer.8.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
2020-11-17 12:52:04,781 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,781 |vlbert.encoder.layer.8.output.dense.bias                     |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,781 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,781 |vlbert.encoder.layer.8.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,781 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,781 |vlbert.encoder.layer.8.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,781 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,781 |vlbert.encoder.layer.9.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,781 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,781 |vlbert.encoder.layer.9.attention.self.query.bias             |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,782 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,782 |vlbert.encoder.layer.9.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,782 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,782 |vlbert.encoder.layer.9.attention.self.key.bias               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,782 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,782 |vlbert.encoder.layer.9.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,782 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,782 |vlbert.encoder.layer.9.attention.self.value.bias             |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,782 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,782 |vlbert.encoder.layer.9.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,782 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,782 |vlbert.encoder.layer.9.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,782 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,782 |vlbert.encoder.layer.9.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,782 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,782 |vlbert.encoder.layer.9.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,782 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,783 |vlbert.encoder.layer.9.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
2020-11-17 12:52:04,783 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,783 |vlbert.encoder.layer.9.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
2020-11-17 12:52:04,783 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,783 |vlbert.encoder.layer.9.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
2020-11-17 12:52:04,783 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,783 |vlbert.encoder.layer.9.output.dense.bias                     |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,783 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,783 |vlbert.encoder.layer.9.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,783 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,783 |vlbert.encoder.layer.9.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,783 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,783 |vlbert.encoder.layer.10.attention.self.query.weight          |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,783 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,783 |vlbert.encoder.layer.10.attention.self.query.bias            |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,784 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,784 |vlbert.encoder.layer.10.attention.self.key.weight            |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,784 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,784 |vlbert.encoder.layer.10.attention.self.key.bias              |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,784 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,784 |vlbert.encoder.layer.10.attention.self.value.weight          |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,784 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,784 |vlbert.encoder.layer.10.attention.self.value.bias            |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,784 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,784 |vlbert.encoder.layer.10.attention.output.dense.weight        |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,784 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,784 |vlbert.encoder.layer.10.attention.output.dense.bias          |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,784 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,784 |vlbert.encoder.layer.10.attention.output.LayerNorm.weight    |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,784 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,784 |vlbert.encoder.layer.10.attention.output.LayerNorm.bias      |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,785 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,785 |vlbert.encoder.layer.10.intermediate.dense.weight            |torch.float32    |(3072, 768)     |2359296     |
2020-11-17 12:52:04,785 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,785 |vlbert.encoder.layer.10.intermediate.dense.bias              |torch.float32    |(3072,)         |3072        |
2020-11-17 12:52:04,785 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,785 |vlbert.encoder.layer.10.output.dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
2020-11-17 12:52:04,785 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,785 |vlbert.encoder.layer.10.output.dense.bias                    |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,785 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,785 |vlbert.encoder.layer.10.output.LayerNorm.weight              |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,785 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,785 |vlbert.encoder.layer.10.output.LayerNorm.bias                |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,785 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,785 |vlbert.encoder.layer.11.attention.self.query.weight          |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,785 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,785 |vlbert.encoder.layer.11.attention.self.query.bias            |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,786 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,786 |vlbert.encoder.layer.11.attention.self.key.weight            |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,786 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,786 |vlbert.encoder.layer.11.attention.self.key.bias              |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,786 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,786 |vlbert.encoder.layer.11.attention.self.value.weight          |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,786 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,786 |vlbert.encoder.layer.11.attention.self.value.bias            |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,786 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,786 |vlbert.encoder.layer.11.attention.output.dense.weight        |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,786 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,786 |vlbert.encoder.layer.11.attention.output.dense.bias          |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,786 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,786 |vlbert.encoder.layer.11.attention.output.LayerNorm.weight    |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,786 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,787 |vlbert.encoder.layer.11.attention.output.LayerNorm.bias      |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,787 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,787 |vlbert.encoder.layer.11.intermediate.dense.weight            |torch.float32    |(3072, 768)     |2359296     |
2020-11-17 12:52:04,787 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,787 |vlbert.encoder.layer.11.intermediate.dense.bias              |torch.float32    |(3072,)         |3072        |
2020-11-17 12:52:04,787 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,787 |vlbert.encoder.layer.11.output.dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
2020-11-17 12:52:04,787 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,787 |vlbert.encoder.layer.11.output.dense.bias                    |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,787 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,787 |vlbert.encoder.layer.11.output.LayerNorm.weight              |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,787 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,787 |vlbert.encoder.layer.11.output.LayerNorm.bias                |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,787 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,787 |final_mlp.0.dense.weight                                     |torch.float32    |(768, 768)      |589824      |
2020-11-17 12:52:04,787 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,787 |final_mlp.0.dense.bias                                       |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,787 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,787 |final_mlp.0.LayerNorm.weight                                 |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,787 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,787 |final_mlp.0.LayerNorm.bias                                   |torch.float32    |(768,)          |768         |
2020-11-17 12:52:04,787 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,787 |final_mlp.2.weight                                           |torch.float32    |(3129, 768)     |2403072     |
2020-11-17 12:52:04,787 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,787 |final_mlp.2.bias                                             |torch.float32    |(3129,)         |3129        |
2020-11-17 12:52:04,787 ---------------------------------------------------------------------------------------------------------------
2020-11-17 12:52:04,789 >> # TrainableParams:       	115.04	M
2020-11-17 12:52:04,789 >> # NonTrainableParams:    	0.00	M
2020-11-17 12:52:04,789 >> # TotalParams:           	115.04	M
2020-11-17 12:52:37,573 loading vocabulary file ./model/pretrained_model/bert-base-uncased/vocab.txt
2020-11-17 12:52:43,442 loading vocabulary file ./model/pretrained_model/bert-base-uncased/vocab.txt
2020-11-17 12:53:38,947 Epoch[3] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-SoftAcc=0.812500,	AnsLoss=1.941168,	
2020-11-17 12:54:26,471 Epoch[3] Batch [100]	Speed: 67.34 samples/s ETA: 0 d  5 h 24 m	Data: 0.039 Tran: 0.004 F: 0.081 B: 0.389 O: 0.042 M: 0.013	Train-SoftAcc=0.695452,	AnsLoss=2.917076,	
2020-11-17 12:55:17,555 Epoch[3] Batch [200]	Speed: 62.64 samples/s ETA: 0 d  5 h 48 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.420 O: 0.041 M: 0.013	Train-SoftAcc=0.688308,	AnsLoss=2.947419,	
2020-11-17 12:56:06,347 Epoch[3] Batch [300]	Speed: 65.59 samples/s ETA: 0 d  5 h 32 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.397 O: 0.041 M: 0.013	Train-SoftAcc=0.689462,	AnsLoss=2.931455,	
2020-11-17 12:56:56,375 Epoch[3] Batch [400]	Speed: 63.97 samples/s ETA: 0 d  5 h 39 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.410 O: 0.040 M: 0.013	Train-SoftAcc=0.689838,	AnsLoss=2.908176,	
2020-11-17 12:57:45,686 Epoch[3] Batch [500]	Speed: 64.89 samples/s ETA: 0 d  5 h 33 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.041 M: 0.013	Train-SoftAcc=0.692185,	AnsLoss=2.901009,	
2020-11-17 12:58:35,551 Epoch[3] Batch [600]	Speed: 64.18 samples/s ETA: 0 d  5 h 36 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.013	Train-SoftAcc=0.693069,	AnsLoss=2.906476,	
2020-11-17 12:59:25,335 Epoch[3] Batch [700]	Speed: 64.28 samples/s ETA: 0 d  5 h 35 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.014	Train-SoftAcc=0.693960,	AnsLoss=2.901761,	
2020-11-17 13:00:13,968 Epoch[3] Batch [800]	Speed: 65.80 samples/s ETA: 0 d  5 h 26 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.396 O: 0.040 M: 0.013	Train-SoftAcc=0.694855,	AnsLoss=2.903067,	
2020-11-17 13:01:03,955 Epoch[3] Batch [900]	Speed: 64.02 samples/s ETA: 0 d  5 h 35 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.410 O: 0.039 M: 0.014	Train-SoftAcc=0.694506,	AnsLoss=2.894410,	
2020-11-17 13:01:54,414 Epoch[3] Batch [1000]	Speed: 63.42 samples/s ETA: 0 d  5 h 37 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.414 O: 0.040 M: 0.013	Train-SoftAcc=0.695105,	AnsLoss=2.888603,	
2020-11-17 13:02:43,314 Epoch[3] Batch [1100]	Speed: 65.44 samples/s ETA: 0 d  5 h 26 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.399 O: 0.040 M: 0.013	Train-SoftAcc=0.694318,	AnsLoss=2.891229,	
2020-11-17 13:03:33,139 Epoch[3] Batch [1200]	Speed: 64.23 samples/s ETA: 0 d  5 h 31 m	Data: 0.005 Tran: 0.004 F: 0.028 B: 0.407 O: 0.041 M: 0.013	Train-SoftAcc=0.694432,	AnsLoss=2.893533,	
2020-11-17 13:04:21,929 Epoch[3] Batch [1300]	Speed: 65.59 samples/s ETA: 0 d  5 h 23 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.398 O: 0.040 M: 0.014	Train-SoftAcc=0.694913,	AnsLoss=2.894766,	
2020-11-17 13:05:11,574 Epoch[3] Batch [1400]	Speed: 64.46 samples/s ETA: 0 d  5 h 28 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.013	Train-SoftAcc=0.695372,	AnsLoss=2.890788,	
2020-11-17 13:06:00,975 Epoch[3] Batch [1500]	Speed: 64.78 samples/s ETA: 0 d  5 h 26 m	Data: 0.005 Tran: 0.004 F: 0.028 B: 0.403 O: 0.041 M: 0.013	Train-SoftAcc=0.695293,	AnsLoss=2.895543,	
2020-11-17 13:06:50,194 Epoch[3] Batch [1600]	Speed: 65.02 samples/s ETA: 0 d  5 h 24 m	Data: 0.005 Tran: 0.004 F: 0.028 B: 0.401 O: 0.040 M: 0.013	Train-SoftAcc=0.694859,	AnsLoss=2.897222,	
2020-11-17 13:07:40,283 Epoch[3] Batch [1700]	Speed: 63.89 samples/s ETA: 0 d  5 h 29 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.411 O: 0.040 M: 0.014	Train-SoftAcc=0.695275,	AnsLoss=2.898485,	
2020-11-17 13:08:29,823 Epoch[3] Batch [1800]	Speed: 64.60 samples/s ETA: 0 d  5 h 24 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.014	Train-SoftAcc=0.695753,	AnsLoss=2.894206,	
2020-11-17 13:09:18,631 Epoch[3] Batch [1900]	Speed: 65.56 samples/s ETA: 0 d  5 h 19 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.398 O: 0.040 M: 0.014	Train-SoftAcc=0.695317,	AnsLoss=2.897249,	
2020-11-17 13:10:09,053 Epoch[3] Batch [2000]	Speed: 63.47 samples/s ETA: 0 d  5 h 28 m	Data: 0.005 Tran: 0.004 F: 0.028 B: 0.413 O: 0.041 M: 0.013	Train-SoftAcc=0.695296,	AnsLoss=2.894423,	
2020-11-17 13:10:59,444 Epoch[3] Batch [2100]	Speed: 63.50 samples/s ETA: 0 d  5 h 27 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.414 O: 0.040 M: 0.014	Train-SoftAcc=0.694711,	AnsLoss=2.896283,	
2020-11-17 13:11:49,399 Epoch[3] Batch [2200]	Speed: 64.06 samples/s ETA: 0 d  5 h 24 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.409 O: 0.041 M: 0.013	Train-SoftAcc=0.694318,	AnsLoss=2.890917,	
2020-11-17 13:12:39,369 Epoch[3] Batch [2300]	Speed: 64.04 samples/s ETA: 0 d  5 h 23 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.410 O: 0.039 M: 0.014	Train-SoftAcc=0.694772,	AnsLoss=2.884617,	
2020-11-17 13:13:29,914 Epoch[3] Batch [2400]	Speed: 63.31 samples/s ETA: 0 d  5 h 26 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.415 O: 0.040 M: 0.014	Train-SoftAcc=0.694533,	AnsLoss=2.883227,	
2020-11-17 13:14:19,573 Epoch[3] Batch [2500]	Speed: 64.44 samples/s ETA: 0 d  5 h 19 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.014	Train-SoftAcc=0.694131,	AnsLoss=2.885220,	
2020-11-17 13:15:09,306 Epoch[3] Batch [2600]	Speed: 64.34 samples/s ETA: 0 d  5 h 19 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.040 M: 0.014	Train-SoftAcc=0.694066,	AnsLoss=2.882591,	
2020-11-17 13:15:58,360 Epoch[3] Batch [2700]	Speed: 65.24 samples/s ETA: 0 d  5 h 14 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.400 O: 0.040 M: 0.014	Train-SoftAcc=0.693945,	AnsLoss=2.882036,	
2020-11-17 13:16:48,163 Epoch[3] Batch [2800]	Speed: 64.25 samples/s ETA: 0 d  5 h 18 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.014	Train-SoftAcc=0.694312,	AnsLoss=2.879543,	
2020-11-17 13:17:37,475 Epoch[3] Batch [2900]	Speed: 64.90 samples/s ETA: 0 d  5 h 14 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.039 M: 0.014	Train-SoftAcc=0.695083,	AnsLoss=2.873322,	
2020-11-17 13:18:27,859 Epoch[3] Batch [3000]	Speed: 63.51 samples/s ETA: 0 d  5 h 20 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.414 O: 0.040 M: 0.013	Train-SoftAcc=0.695350,	AnsLoss=2.869640,	
2020-11-17 13:19:17,933 Epoch[3] Batch [3100]	Speed: 63.91 samples/s ETA: 0 d  5 h 17 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.411 O: 0.040 M: 0.014	Train-SoftAcc=0.695308,	AnsLoss=2.866935,	
2020-11-17 13:20:07,230 Epoch[3] Batch [3200]	Speed: 64.91 samples/s ETA: 0 d  5 h 11 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.040 M: 0.013	Train-SoftAcc=0.695603,	AnsLoss=2.864340,	
2020-11-17 13:20:57,587 Epoch[3] Batch [3300]	Speed: 63.55 samples/s ETA: 0 d  5 h 17 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.413 O: 0.040 M: 0.014	Train-SoftAcc=0.695982,	AnsLoss=2.861742,	
2020-11-17 13:21:47,059 Epoch[3] Batch [3400]	Speed: 64.68 samples/s ETA: 0 d  5 h 11 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.014	Train-SoftAcc=0.696086,	AnsLoss=2.864287,	
2020-11-17 13:22:36,896 Epoch[3] Batch [3500]	Speed: 64.21 samples/s ETA: 0 d  5 h 12 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.014	Train-SoftAcc=0.695963,	AnsLoss=2.862737,	
2020-11-17 13:23:27,016 Epoch[3] Batch [3600]	Speed: 63.85 samples/s ETA: 0 d  5 h 13 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.411 O: 0.040 M: 0.014	Train-SoftAcc=0.696197,	AnsLoss=2.861839,	
2020-11-17 13:24:16,316 Epoch[3] Batch [3700]	Speed: 64.91 samples/s ETA: 0 d  5 h  7 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.040 M: 0.013	Train-SoftAcc=0.696384,	AnsLoss=2.859562,	
2020-11-17 13:25:06,713 Epoch[3] Batch [3800]	Speed: 63.50 samples/s ETA: 0 d  5 h 13 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.414 O: 0.040 M: 0.014	Train-SoftAcc=0.696655,	AnsLoss=2.858100,	
2020-11-17 13:25:56,855 Epoch[3] Batch [3900]	Speed: 63.82 samples/s ETA: 0 d  5 h 11 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.411 O: 0.040 M: 0.013	Train-SoftAcc=0.697065,	AnsLoss=2.857683,	
2020-11-17 13:26:46,637 Epoch[3] Batch [4000]	Speed: 64.28 samples/s ETA: 0 d  5 h  8 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.014	Train-SoftAcc=0.697337,	AnsLoss=2.856475,	
2020-11-17 13:27:36,681 Epoch[3] Batch [4100]	Speed: 63.95 samples/s ETA: 0 d  5 h  8 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.410 O: 0.040 M: 0.014	Train-SoftAcc=0.697824,	AnsLoss=2.855249,	
2020-11-17 13:28:26,670 Epoch[3] Batch [4200]	Speed: 64.02 samples/s ETA: 0 d  5 h  7 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.410 O: 0.040 M: 0.013	Train-SoftAcc=0.698136,	AnsLoss=2.852252,	
2020-11-17 13:29:15,691 Epoch[3] Batch [4300]	Speed: 65.28 samples/s ETA: 0 d  5 h  0 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.400 O: 0.040 M: 0.014	Train-SoftAcc=0.698044,	AnsLoss=2.852675,	
2020-11-17 13:30:04,782 Epoch[3] Batch [4400]	Speed: 65.19 samples/s ETA: 0 d  5 h  0 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.401 O: 0.040 M: 0.014	Train-SoftAcc=0.698219,	AnsLoss=2.851249,	
2020-11-17 13:30:54,367 Epoch[3] Batch [4500]	Speed: 64.54 samples/s ETA: 0 d  5 h  2 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.041 M: 0.013	Train-SoftAcc=0.698142,	AnsLoss=2.850794,	
2020-11-17 13:31:44,039 Epoch[3] Batch [4600]	Speed: 64.42 samples/s ETA: 0 d  5 h  2 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.040 M: 0.014	Train-SoftAcc=0.698412,	AnsLoss=2.851129,	
2020-11-17 13:32:33,616 Epoch[3] Batch [4700]	Speed: 64.55 samples/s ETA: 0 d  5 h  1 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.406 O: 0.039 M: 0.014	Train-SoftAcc=0.698734,	AnsLoss=2.850398,	
2020-11-17 13:33:23,466 Epoch[3] Batch [4800]	Speed: 64.19 samples/s ETA: 0 d  5 h  1 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.014	Train-SoftAcc=0.698858,	AnsLoss=2.848817,	
2020-11-17 13:34:12,543 Epoch[3] Batch [4900]	Speed: 65.20 samples/s ETA: 0 d  4 h 56 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.401 O: 0.040 M: 0.013	Train-SoftAcc=0.699147,	AnsLoss=2.846350,	
2020-11-17 13:35:02,365 Epoch[3] Batch [5000]	Speed: 64.23 samples/s ETA: 0 d  5 h  0 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.040 M: 0.013	Train-SoftAcc=0.699288,	AnsLoss=2.846063,	
2020-11-17 13:35:52,443 Epoch[3] Batch [5100]	Speed: 63.90 samples/s ETA: 0 d  5 h  0 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.411 O: 0.040 M: 0.014	Train-SoftAcc=0.699451,	AnsLoss=2.843956,	
2020-11-17 13:36:42,248 Epoch[3] Batch [5200]	Speed: 64.25 samples/s ETA: 0 d  4 h 58 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.014	Train-SoftAcc=0.699718,	AnsLoss=2.844045,	
2020-11-17 13:37:32,743 Epoch[3] Batch [5300]	Speed: 63.37 samples/s ETA: 0 d  5 h  1 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.415 O: 0.040 M: 0.013	Train-SoftAcc=0.699910,	AnsLoss=2.840666,	
2020-11-17 13:38:22,067 Epoch[3] Batch [5400]	Speed: 64.88 samples/s ETA: 0 d  4 h 53 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.040 M: 0.014	Train-SoftAcc=0.700407,	AnsLoss=2.837474,	
2020-11-17 13:39:11,601 Epoch[3] Batch [5500]	Speed: 64.60 samples/s ETA: 0 d  4 h 54 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.013	Train-SoftAcc=0.700665,	AnsLoss=2.835659,	
2020-11-17 13:40:01,150 Epoch[3] Batch [5600]	Speed: 64.58 samples/s ETA: 0 d  4 h 53 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.014	Train-SoftAcc=0.700825,	AnsLoss=2.833670,	
2020-11-17 13:40:51,010 Epoch[3] Batch [5700]	Speed: 64.18 samples/s ETA: 0 d  4 h 54 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.014	Train-SoftAcc=0.701006,	AnsLoss=2.832493,	
2020-11-17 13:41:40,343 Epoch[3] Batch [5800]	Speed: 64.87 samples/s ETA: 0 d  4 h 50 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.040 M: 0.014	Train-SoftAcc=0.701088,	AnsLoss=2.832137,	
2020-11-17 13:42:29,529 Epoch[3] Batch [5900]	Speed: 65.06 samples/s ETA: 0 d  4 h 48 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.014	Train-SoftAcc=0.701097,	AnsLoss=2.832565,	
2020-11-17 13:43:19,739 Epoch[3] Batch [6000]	Speed: 63.73 samples/s ETA: 0 d  4 h 53 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.412 O: 0.039 M: 0.014	Train-SoftAcc=0.701208,	AnsLoss=2.830437,	
2020-11-17 13:44:09,273 Epoch[3] Batch [6100]	Speed: 64.60 samples/s ETA: 0 d  4 h 49 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.014	Train-SoftAcc=0.701366,	AnsLoss=2.829901,	
2020-11-17 13:44:58,679 Epoch[3] Batch [6200]	Speed: 64.77 samples/s ETA: 0 d  4 h 47 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.404 O: 0.040 M: 0.014	Train-SoftAcc=0.701348,	AnsLoss=2.830534,	
2020-11-17 13:45:48,305 Epoch[3] Batch [6300]	Speed: 64.48 samples/s ETA: 0 d  4 h 48 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.407 O: 0.039 M: 0.014	Train-SoftAcc=0.701648,	AnsLoss=2.829592,	
2020-11-17 13:46:38,198 Epoch[3] Batch [6400]	Speed: 64.14 samples/s ETA: 0 d  4 h 48 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.014	Train-SoftAcc=0.701707,	AnsLoss=2.828645,	
2020-11-17 13:47:27,845 Epoch[3] Batch [6500]	Speed: 64.46 samples/s ETA: 0 d  4 h 46 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.039 M: 0.014	Train-SoftAcc=0.701937,	AnsLoss=2.827794,	
2020-11-17 13:48:17,301 Epoch[3] Batch [6600]	Speed: 64.70 samples/s ETA: 0 d  4 h 44 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.404 O: 0.040 M: 0.014	Train-SoftAcc=0.702250,	AnsLoss=2.826068,	
2020-11-17 13:49:06,961 Epoch[3] Batch [6700]	Speed: 64.44 samples/s ETA: 0 d  4 h 44 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.014	Train-SoftAcc=0.702207,	AnsLoss=2.825738,	
2020-11-17 13:49:56,708 Epoch[3] Batch [6800]	Speed: 64.33 samples/s ETA: 0 d  4 h 44 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.039 M: 0.014	Train-SoftAcc=0.702332,	AnsLoss=2.823459,	
2020-11-17 13:50:45,851 Epoch[3] Batch [6900]	Speed: 65.12 samples/s ETA: 0 d  4 h 40 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.401 O: 0.040 M: 0.014	Train-SoftAcc=0.702475,	AnsLoss=2.823059,	
2020-11-17 13:51:35,129 Epoch[3] Batch [7000]	Speed: 64.94 samples/s ETA: 0 d  4 h 40 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.039 M: 0.014	Train-SoftAcc=0.702419,	AnsLoss=2.822291,	
2020-11-17 13:52:24,563 Epoch[3] Batch [7100]	Speed: 64.73 samples/s ETA: 0 d  4 h 40 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.404 O: 0.040 M: 0.013	Train-SoftAcc=0.702893,	AnsLoss=2.820329,	
2020-11-17 13:53:14,847 Epoch[3] Batch [7200]	Speed: 63.64 samples/s ETA: 0 d  4 h 44 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.412 O: 0.040 M: 0.013	Train-SoftAcc=0.703193,	AnsLoss=2.819687,	
2020-11-17 13:54:03,797 Epoch[3] Batch [7300]	Speed: 65.37 samples/s ETA: 0 d  4 h 36 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.399 O: 0.040 M: 0.014	Train-SoftAcc=0.703396,	AnsLoss=2.818857,	
2020-11-17 13:54:52,741 Epoch[3] Batch [7400]	Speed: 65.38 samples/s ETA: 0 d  4 h 35 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.400 O: 0.039 M: 0.014	Train-SoftAcc=0.703571,	AnsLoss=2.817494,	
2020-11-17 13:55:42,202 Epoch[3] Batch [7500]	Speed: 64.70 samples/s ETA: 0 d  4 h 37 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.405 O: 0.040 M: 0.014	Train-SoftAcc=0.703569,	AnsLoss=2.817083,	
2020-11-17 13:56:31,227 Epoch[3] Batch [7600]	Speed: 65.27 samples/s ETA: 0 d  4 h 33 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.399 O: 0.040 M: 0.013	Train-SoftAcc=0.703688,	AnsLoss=2.816910,	
2020-11-17 13:57:20,413 Epoch[3] Batch [7700]	Speed: 65.06 samples/s ETA: 0 d  4 h 34 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.401 O: 0.040 M: 0.013	Train-SoftAcc=0.703743,	AnsLoss=2.816795,	
2020-11-17 13:58:09,640 Epoch[3] Batch [7800]	Speed: 65.01 samples/s ETA: 0 d  4 h 33 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.013	Train-SoftAcc=0.703821,	AnsLoss=2.816391,	
2020-11-17 13:58:58,978 Epoch[3] Batch [7900]	Speed: 64.86 samples/s ETA: 0 d  4 h 33 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.040 M: 0.014	Train-SoftAcc=0.704119,	AnsLoss=2.814457,	
2020-11-17 13:59:47,782 Epoch[3] Batch [8000]	Speed: 65.57 samples/s ETA: 0 d  4 h 29 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.398 O: 0.040 M: 0.014	Train-SoftAcc=0.704320,	AnsLoss=2.812788,	
2020-11-17 14:00:37,892 Epoch[3] Batch [8100]	Speed: 63.86 samples/s ETA: 0 d  4 h 35 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.411 O: 0.040 M: 0.014	Train-SoftAcc=0.704459,	AnsLoss=2.811804,	
2020-11-17 14:01:27,370 Epoch[3] Batch [8200]	Speed: 64.68 samples/s ETA: 0 d  4 h 31 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.405 O: 0.040 M: 0.014	Train-SoftAcc=0.704556,	AnsLoss=2.811229,	
2020-11-17 14:02:16,886 Epoch[3] Batch [8300]	Speed: 64.63 samples/s ETA: 0 d  4 h 30 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.039 M: 0.014	Train-SoftAcc=0.704596,	AnsLoss=2.810377,	
2020-11-17 14:03:06,988 Epoch[3] Batch [8400]	Speed: 63.87 samples/s ETA: 0 d  4 h 33 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.411 O: 0.039 M: 0.014	Train-SoftAcc=0.704605,	AnsLoss=2.810233,	
2020-11-17 14:03:57,116 Epoch[3] Batch [8500]	Speed: 63.84 samples/s ETA: 0 d  4 h 32 m	Data: 0.005 Tran: 0.004 F: 0.028 B: 0.410 O: 0.040 M: 0.013	Train-SoftAcc=0.704671,	AnsLoss=2.809826,	
2020-11-17 14:04:47,349 Epoch[3] Batch [8600]	Speed: 63.70 samples/s ETA: 0 d  4 h 32 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.412 O: 0.040 M: 0.013	Train-SoftAcc=0.704761,	AnsLoss=2.809713,	
2020-11-17 14:05:38,066 Epoch[3] Batch [8700]	Speed: 63.10 samples/s ETA: 0 d  4 h 34 m	Data: 0.005 Tran: 0.005 F: 0.028 B: 0.416 O: 0.040 M: 0.013	Train-SoftAcc=0.704809,	AnsLoss=2.809761,	
2020-11-17 14:06:27,603 Epoch[3] Batch [8800]	Speed: 64.60 samples/s ETA: 0 d  4 h 26 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.014	Train-SoftAcc=0.705078,	AnsLoss=2.808177,	
2020-11-17 14:07:17,224 Epoch[3] Batch [8900]	Speed: 64.49 samples/s ETA: 0 d  4 h 26 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.013	Train-SoftAcc=0.705211,	AnsLoss=2.807276,	
2020-11-17 14:08:06,909 Epoch[3] Batch [9000]	Speed: 64.41 samples/s ETA: 0 d  4 h 26 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.040 M: 0.014	Train-SoftAcc=0.705349,	AnsLoss=2.806397,	
2020-11-17 14:08:56,119 Epoch[3] Batch [9100]	Speed: 65.03 samples/s ETA: 0 d  4 h 22 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.401 O: 0.040 M: 0.013	Train-SoftAcc=0.705597,	AnsLoss=2.805004,	
2020-11-17 14:09:46,004 Epoch[3] Batch [9200]	Speed: 64.15 samples/s ETA: 0 d  4 h 25 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.013	Train-SoftAcc=0.705640,	AnsLoss=2.804959,	
2020-11-17 14:10:35,973 Epoch[3] Batch [9300]	Speed: 64.04 samples/s ETA: 0 d  4 h 25 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.409 O: 0.040 M: 0.014	Train-SoftAcc=0.705869,	AnsLoss=2.804177,	
2020-11-17 14:11:25,826 Epoch[3] Batch [9400]	Speed: 64.26 samples/s ETA: 0 d  4 h 23 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.014	Train-SoftAcc=0.705966,	AnsLoss=2.803679,	
2020-11-17 14:12:15,339 Epoch[3] Batch [9500]	Speed: 64.63 samples/s ETA: 0 d  4 h 21 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.014	Train-SoftAcc=0.706098,	AnsLoss=2.802975,	
2020-11-17 14:13:04,372 Epoch[3] Batch [9600]	Speed: 65.26 samples/s ETA: 0 d  4 h 17 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.400 O: 0.040 M: 0.014	Train-SoftAcc=0.706162,	AnsLoss=2.802804,	
2020-11-17 14:13:52,927 Epoch[3] Batch [9700]	Speed: 65.91 samples/s ETA: 0 d  4 h 14 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.396 O: 0.039 M: 0.014	Train-SoftAcc=0.706308,	AnsLoss=2.801650,	
2020-11-17 14:14:42,394 Epoch[3] Batch [9800]	Speed: 64.69 samples/s ETA: 0 d  4 h 18 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.404 O: 0.040 M: 0.014	Train-SoftAcc=0.706402,	AnsLoss=2.801224,	
2020-11-17 14:15:31,931 Epoch[3] Batch [9900]	Speed: 64.60 samples/s ETA: 0 d  4 h 17 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.013	Train-SoftAcc=0.706473,	AnsLoss=2.800755,	
2020-11-17 14:16:21,070 Epoch[3] Batch [10000]	Speed: 65.12 samples/s ETA: 0 d  4 h 14 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.014	Train-SoftAcc=0.706632,	AnsLoss=2.799514,	
2020-11-17 14:17:11,127 Epoch[3] Batch [10100]	Speed: 63.93 samples/s ETA: 0 d  4 h 18 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.411 O: 0.040 M: 0.013	Train-SoftAcc=0.706789,	AnsLoss=2.798677,	
2020-11-17 14:18:00,193 Epoch[3] Batch [10200]	Speed: 65.22 samples/s ETA: 0 d  4 h 12 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.400 O: 0.040 M: 0.014	Train-SoftAcc=0.706838,	AnsLoss=2.797952,	
2020-11-17 14:18:50,079 Epoch[3] Batch [10300]	Speed: 64.15 samples/s ETA: 0 d  4 h 16 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.409 O: 0.039 M: 0.014	Train-SoftAcc=0.707066,	AnsLoss=2.796093,	
2020-11-17 14:19:40,441 Epoch[3] Batch [10400]	Speed: 63.54 samples/s ETA: 0 d  4 h 17 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.414 O: 0.040 M: 0.014	Train-SoftAcc=0.707135,	AnsLoss=2.795316,	
2020-11-17 14:20:29,754 Epoch[3] Batch [10500]	Speed: 64.89 samples/s ETA: 0 d  4 h 11 m	Data: 0.005 Tran: 0.004 F: 0.028 B: 0.402 O: 0.040 M: 0.013	Train-SoftAcc=0.707400,	AnsLoss=2.793580,	
2020-11-17 14:21:19,845 Epoch[3] Batch [10600]	Speed: 63.89 samples/s ETA: 0 d  4 h 14 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.410 O: 0.040 M: 0.013	Train-SoftAcc=0.707528,	AnsLoss=2.792913,	
2020-11-17 14:22:09,843 Epoch[3] Batch [10700]	Speed: 64.00 samples/s ETA: 0 d  4 h 13 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.410 O: 0.039 M: 0.014	Train-SoftAcc=0.707584,	AnsLoss=2.792104,	
2020-11-17 14:23:00,142 Epoch[3] Batch [10800]	Speed: 63.62 samples/s ETA: 0 d  4 h 14 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.413 O: 0.040 M: 0.014	Train-SoftAcc=0.707901,	AnsLoss=2.789384,	
2020-11-17 14:23:49,917 Epoch[3] Batch [10900]	Speed: 64.29 samples/s ETA: 0 d  4 h 10 m	Data: 0.005 Tran: 0.004 F: 0.028 B: 0.407 O: 0.040 M: 0.013	Train-SoftAcc=0.708083,	AnsLoss=2.788825,	
2020-11-17 14:24:40,233 Epoch[3] Batch [11000]	Speed: 63.60 samples/s ETA: 0 d  4 h 12 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.413 O: 0.039 M: 0.014	Train-SoftAcc=0.708221,	AnsLoss=2.787657,	
2020-11-17 14:25:31,005 Epoch[3] Batch [11100]	Speed: 63.03 samples/s ETA: 0 d  4 h 14 m	Data: 0.005 Tran: 0.004 F: 0.034 B: 0.411 O: 0.040 M: 0.014	Train-SoftAcc=0.708289,	AnsLoss=2.787140,	
2020-11-17 14:26:20,792 Epoch[3] Batch [11200]	Speed: 64.27 samples/s ETA: 0 d  4 h  8 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.014	Train-SoftAcc=0.708473,	AnsLoss=2.785669,	
2020-11-17 14:27:10,580 Epoch[3] Batch [11300]	Speed: 64.27 samples/s ETA: 0 d  4 h  7 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.040 M: 0.013	Train-SoftAcc=0.708491,	AnsLoss=2.785090,	
2020-11-17 14:27:59,924 Epoch[3] Batch [11400]	Speed: 64.85 samples/s ETA: 0 d  4 h  4 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.404 O: 0.040 M: 0.014	Train-SoftAcc=0.708636,	AnsLoss=2.783652,	
2020-11-17 14:28:49,474 Epoch[3] Batch [11500]	Speed: 64.58 samples/s ETA: 0 d  4 h  4 m	Data: 0.005 Tran: 0.004 F: 0.028 B: 0.404 O: 0.040 M: 0.013	Train-SoftAcc=0.708602,	AnsLoss=2.783843,	
2020-11-17 14:29:39,036 Epoch[3] Batch [11600]	Speed: 64.57 samples/s ETA: 0 d  4 h  3 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.014	Train-SoftAcc=0.708605,	AnsLoss=2.783745,	
2020-11-17 14:30:28,613 Epoch[3] Batch [11700]	Speed: 64.55 samples/s ETA: 0 d  4 h  3 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.014	Train-SoftAcc=0.708763,	AnsLoss=2.782987,	
2020-11-17 14:31:18,447 Epoch[3] Batch [11800]	Speed: 64.21 samples/s ETA: 0 d  4 h  3 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.014	Train-SoftAcc=0.708859,	AnsLoss=2.781595,	
2020-11-17 14:32:07,307 Epoch[3] Batch [11900]	Speed: 65.49 samples/s ETA: 0 d  3 h 58 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.399 O: 0.040 M: 0.014	Train-SoftAcc=0.708971,	AnsLoss=2.781166,	
2020-11-17 14:32:56,472 Epoch[3] Batch [12000]	Speed: 65.09 samples/s ETA: 0 d  3 h 58 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.402 O: 0.039 M: 0.014	Train-SoftAcc=0.709067,	AnsLoss=2.780253,	
2020-11-17 14:33:46,568 Epoch[3] Batch [12100]	Speed: 63.88 samples/s ETA: 0 d  4 h  2 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.410 O: 0.040 M: 0.013	Train-SoftAcc=0.709208,	AnsLoss=2.779453,	
2020-11-17 14:34:35,228 Epoch[3] Batch [12200]	Speed: 65.76 samples/s ETA: 0 d  3 h 54 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.396 O: 0.040 M: 0.014	Train-SoftAcc=0.709335,	AnsLoss=2.778347,	
2020-11-17 14:35:24,557 Epoch[3] Batch [12300]	Speed: 64.87 samples/s ETA: 0 d  3 h 57 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.040 M: 0.014	Train-SoftAcc=0.709419,	AnsLoss=2.778131,	
2020-11-17 14:36:14,271 Epoch[3] Batch [12400]	Speed: 64.37 samples/s ETA: 0 d  3 h 58 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.013	Train-SoftAcc=0.709481,	AnsLoss=2.777820,	
2020-11-17 14:37:03,917 Epoch[3] Batch [12500]	Speed: 64.46 samples/s ETA: 0 d  3 h 56 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.014	Train-SoftAcc=0.709586,	AnsLoss=2.776678,	
2020-11-17 14:37:53,652 Epoch[3] Batch [12600]	Speed: 64.34 samples/s ETA: 0 d  3 h 56 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.040 M: 0.014	Train-SoftAcc=0.709625,	AnsLoss=2.776546,	
2020-11-17 14:38:43,920 Epoch[3] Batch [12700]	Speed: 63.66 samples/s ETA: 0 d  3 h 58 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.412 O: 0.040 M: 0.013	Train-SoftAcc=0.709652,	AnsLoss=2.776945,	
2020-11-17 14:39:32,816 Epoch[3] Batch [12800]	Speed: 65.45 samples/s ETA: 0 d  3 h 50 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.399 O: 0.040 M: 0.013	Train-SoftAcc=0.709704,	AnsLoss=2.775840,	
2020-11-17 14:40:22,550 Epoch[3] Batch [12900]	Speed: 64.34 samples/s ETA: 0 d  3 h 54 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.040 M: 0.013	Train-SoftAcc=0.709766,	AnsLoss=2.775565,	
2020-11-17 14:41:12,501 Epoch[3] Batch [13000]	Speed: 64.06 samples/s ETA: 0 d  3 h 54 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.409 O: 0.040 M: 0.014	Train-SoftAcc=0.709822,	AnsLoss=2.775362,	
2020-11-17 14:42:01,959 Epoch[3] Batch [13100]	Speed: 64.70 samples/s ETA: 0 d  3 h 51 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.404 O: 0.040 M: 0.014	Train-SoftAcc=0.709907,	AnsLoss=2.774520,	
2020-11-17 14:42:52,491 Epoch[3] Batch [13200]	Speed: 63.33 samples/s ETA: 0 d  3 h 55 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.415 O: 0.040 M: 0.013	Train-SoftAcc=0.710077,	AnsLoss=2.773572,	
2020-11-17 14:43:42,566 Epoch[3] Batch [13300]	Speed: 63.91 samples/s ETA: 0 d  3 h 52 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.411 O: 0.040 M: 0.014	Train-SoftAcc=0.710164,	AnsLoss=2.772922,	
2020-11-17 14:44:32,938 Epoch[3] Batch [13400]	Speed: 63.53 samples/s ETA: 0 d  3 h 52 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.414 O: 0.040 M: 0.013	Train-SoftAcc=0.710295,	AnsLoss=2.772256,	
2020-11-17 14:45:22,280 Epoch[3] Batch [13500]	Speed: 64.85 samples/s ETA: 0 d  3 h 47 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.040 M: 0.014	Train-SoftAcc=0.710351,	AnsLoss=2.771908,	
2020-11-17 14:46:11,403 Epoch[3] Batch [13600]	Speed: 65.17 samples/s ETA: 0 d  3 h 45 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.400 O: 0.040 M: 0.014	Train-SoftAcc=0.710569,	AnsLoss=2.770968,	
2020-11-17 14:47:01,058 Epoch[3] Batch [13700]	Speed: 64.45 samples/s ETA: 0 d  3 h 47 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.014	Train-SoftAcc=0.710585,	AnsLoss=2.771023,	
2020-11-17 14:47:50,941 Epoch[3] Batch [13800]	Speed: 64.15 samples/s ETA: 0 d  3 h 47 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.409 O: 0.039 M: 0.014	Train-SoftAcc=0.710704,	AnsLoss=2.770902,	
2020-11-17 14:48:40,869 Epoch[3] Batch [13900]	Speed: 64.09 samples/s ETA: 0 d  3 h 46 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.409 O: 0.039 M: 0.014	Train-SoftAcc=0.710795,	AnsLoss=2.770675,	
2020-11-17 14:49:29,681 Epoch[3] Batch [14000]	Speed: 65.56 samples/s ETA: 0 d  3 h 40 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.397 O: 0.041 M: 0.013	Train-SoftAcc=0.710872,	AnsLoss=2.770019,	
2020-11-17 14:50:19,815 Epoch[3] Batch [14100]	Speed: 63.83 samples/s ETA: 0 d  3 h 45 m	Data: 0.005 Tran: 0.005 F: 0.028 B: 0.410 O: 0.041 M: 0.013	Train-SoftAcc=0.710921,	AnsLoss=2.768938,	
2020-11-17 14:51:09,486 Epoch[3] Batch [14200]	Speed: 64.43 samples/s ETA: 0 d  3 h 42 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.014	Train-SoftAcc=0.711019,	AnsLoss=2.768439,	
2020-11-17 14:51:58,476 Epoch[3] Batch [14300]	Speed: 65.32 samples/s ETA: 0 d  3 h 39 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.399 O: 0.040 M: 0.014	Train-SoftAcc=0.711197,	AnsLoss=2.767635,	
2020-11-17 14:52:48,253 Epoch[3] Batch [14400]	Speed: 64.29 samples/s ETA: 0 d  3 h 41 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.040 M: 0.013	Train-SoftAcc=0.711344,	AnsLoss=2.766381,	
2020-11-17 14:53:37,873 Epoch[3] Batch [14500]	Speed: 64.49 samples/s ETA: 0 d  3 h 40 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.014	Train-SoftAcc=0.711522,	AnsLoss=2.765343,	
2020-11-17 14:54:27,269 Epoch[3] Batch [14600]	Speed: 64.78 samples/s ETA: 0 d  3 h 38 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.404 O: 0.039 M: 0.014	Train-SoftAcc=0.711624,	AnsLoss=2.765108,	
2020-11-17 14:55:16,189 Epoch[3] Batch [14700]	Speed: 65.41 samples/s ETA: 0 d  3 h 35 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.399 O: 0.040 M: 0.014	Train-SoftAcc=0.711779,	AnsLoss=2.764726,	
2020-11-17 14:56:06,421 Epoch[3] Batch [14800]	Speed: 63.71 samples/s ETA: 0 d  3 h 40 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.412 O: 0.040 M: 0.014	Train-SoftAcc=0.711809,	AnsLoss=2.764473,	
2020-11-17 14:56:55,303 Epoch[3] Batch [14900]	Speed: 65.46 samples/s ETA: 0 d  3 h 33 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.399 O: 0.040 M: 0.014	Train-SoftAcc=0.711859,	AnsLoss=2.764289,	
2020-11-17 14:57:44,603 Epoch[3] Batch [15000]	Speed: 64.91 samples/s ETA: 0 d  3 h 34 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.041 M: 0.013	Train-SoftAcc=0.711933,	AnsLoss=2.763696,	
2020-11-17 14:58:34,123 Epoch[3] Batch [15100]	Speed: 64.62 samples/s ETA: 0 d  3 h 34 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.404 O: 0.040 M: 0.013	Train-SoftAcc=0.712038,	AnsLoss=2.762593,	
2020-11-17 14:59:23,362 Epoch[3] Batch [15200]	Speed: 64.99 samples/s ETA: 0 d  3 h 32 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.014	Train-SoftAcc=0.712160,	AnsLoss=2.762150,	
2020-11-17 15:00:13,107 Epoch[3] Batch [15300]	Speed: 64.33 samples/s ETA: 0 d  3 h 34 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.040 M: 0.014	Train-SoftAcc=0.712274,	AnsLoss=2.761710,	
2020-11-17 15:01:03,411 Epoch[3] Batch [15400]	Speed: 63.61 samples/s ETA: 0 d  3 h 35 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.412 O: 0.040 M: 0.013	Train-SoftAcc=0.712358,	AnsLoss=2.761387,	
2020-11-17 15:01:52,753 Epoch[3] Batch [15500]	Speed: 64.86 samples/s ETA: 0 d  3 h 30 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.404 O: 0.039 M: 0.014	Train-SoftAcc=0.712374,	AnsLoss=2.761053,	
2020-11-17 15:02:42,742 Epoch[3] Batch [15600]	Speed: 64.01 samples/s ETA: 0 d  3 h 32 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.409 O: 0.040 M: 0.014	Train-SoftAcc=0.712408,	AnsLoss=2.760485,	
2020-11-17 15:03:32,933 Epoch[3] Batch [15700]	Speed: 63.76 samples/s ETA: 0 d  3 h 32 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.411 O: 0.040 M: 0.013	Train-SoftAcc=0.712504,	AnsLoss=2.759804,	
2020-11-17 15:04:22,671 Epoch[3] Batch [15800]	Speed: 64.38 samples/s ETA: 0 d  3 h 29 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.407 O: 0.039 M: 0.014	Train-SoftAcc=0.712639,	AnsLoss=2.758981,	
2020-11-17 15:05:13,070 Epoch[3] Batch [15900]	Speed: 63.50 samples/s ETA: 0 d  3 h 31 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.413 O: 0.040 M: 0.014	Train-SoftAcc=0.712764,	AnsLoss=2.758696,	
2020-11-17 15:06:02,674 Epoch[3] Batch [16000]	Speed: 64.51 samples/s ETA: 0 d  3 h 27 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.013	Train-SoftAcc=0.712833,	AnsLoss=2.758495,	
2020-11-17 15:06:52,436 Epoch[3] Batch [16100]	Speed: 64.31 samples/s ETA: 0 d  3 h 27 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.408 O: 0.039 M: 0.014	Train-SoftAcc=0.712918,	AnsLoss=2.757437,	
2020-11-17 15:07:42,154 Epoch[3] Batch [16200]	Speed: 64.37 samples/s ETA: 0 d  3 h 26 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.407 O: 0.039 M: 0.014	Train-SoftAcc=0.713083,	AnsLoss=2.756558,	
2020-11-17 15:08:32,002 Epoch[3] Batch [16300]	Speed: 64.20 samples/s ETA: 0 d  3 h 26 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.409 O: 0.039 M: 0.014	Train-SoftAcc=0.713205,	AnsLoss=2.755743,	
2020-11-17 15:09:21,738 Epoch[3] Batch [16400]	Speed: 64.34 samples/s ETA: 0 d  3 h 25 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.408 O: 0.040 M: 0.014	Train-SoftAcc=0.713310,	AnsLoss=2.755247,	
2020-11-17 15:10:11,526 Epoch[3] Batch [16500]	Speed: 64.27 samples/s ETA: 0 d  3 h 24 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.013	Train-SoftAcc=0.713387,	AnsLoss=2.754788,	
2020-11-17 15:11:00,901 Epoch[3] Batch [16600]	Speed: 64.81 samples/s ETA: 0 d  3 h 21 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.040 M: 0.014	Train-SoftAcc=0.713415,	AnsLoss=2.754412,	
2020-11-17 15:11:50,779 Epoch[3] Batch [16700]	Speed: 64.16 samples/s ETA: 0 d  3 h 23 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.409 O: 0.039 M: 0.014	Train-SoftAcc=0.713471,	AnsLoss=2.754017,	
2020-11-17 15:12:39,915 Epoch[3] Batch [16800]	Speed: 65.13 samples/s ETA: 0 d  3 h 19 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.401 O: 0.040 M: 0.014	Train-SoftAcc=0.713572,	AnsLoss=2.753307,	
2020-11-17 15:13:29,898 Epoch[3] Batch [16900]	Speed: 64.02 samples/s ETA: 0 d  3 h 21 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.410 O: 0.039 M: 0.014	Train-SoftAcc=0.713634,	AnsLoss=2.752612,	
2020-11-17 15:14:19,928 Epoch[3] Batch [17000]	Speed: 63.96 samples/s ETA: 0 d  3 h 21 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.410 O: 0.040 M: 0.013	Train-SoftAcc=0.713696,	AnsLoss=2.752261,	
2020-11-17 15:15:09,178 Epoch[3] Batch [17100]	Speed: 64.98 samples/s ETA: 0 d  3 h 17 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.014	Train-SoftAcc=0.713767,	AnsLoss=2.751599,	
2020-11-17 15:15:59,108 Epoch[3] Batch [17200]	Speed: 64.09 samples/s ETA: 0 d  3 h 19 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.410 O: 0.039 M: 0.014	Train-SoftAcc=0.713878,	AnsLoss=2.750573,	
2020-11-17 15:16:49,285 Epoch[3] Batch [17300]	Speed: 63.78 samples/s ETA: 0 d  3 h 19 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.412 O: 0.039 M: 0.014	Train-SoftAcc=0.713952,	AnsLoss=2.750172,	
2020-11-17 15:17:39,509 Epoch[3] Batch [17400]	Speed: 63.72 samples/s ETA: 0 d  3 h 18 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.412 O: 0.040 M: 0.014	Train-SoftAcc=0.714079,	AnsLoss=2.749459,	
2020-11-17 15:18:29,272 Epoch[3] Batch [17500]	Speed: 64.31 samples/s ETA: 0 d  3 h 15 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.040 M: 0.013	Train-SoftAcc=0.714142,	AnsLoss=2.748974,	
2020-11-17 15:19:19,162 Epoch[3] Batch [17600]	Speed: 64.14 samples/s ETA: 0 d  3 h 15 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.409 O: 0.040 M: 0.013	Train-SoftAcc=0.714221,	AnsLoss=2.748596,	
2020-11-17 15:20:08,308 Epoch[3] Batch [17700]	Speed: 65.11 samples/s ETA: 0 d  3 h 11 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.401 O: 0.040 M: 0.013	Train-SoftAcc=0.714284,	AnsLoss=2.748342,	
2020-11-17 15:20:58,374 Epoch[3] Batch [17800]	Speed: 63.92 samples/s ETA: 0 d  3 h 14 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.410 O: 0.040 M: 0.013	Train-SoftAcc=0.714336,	AnsLoss=2.748041,	
2020-11-17 15:21:48,604 Epoch[3] Batch [17900]	Speed: 63.73 samples/s ETA: 0 d  3 h 14 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.412 O: 0.040 M: 0.013	Train-SoftAcc=0.714366,	AnsLoss=2.747379,	
2020-11-17 15:22:37,995 Epoch[3] Batch [18000]	Speed: 64.79 samples/s ETA: 0 d  3 h 10 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.404 O: 0.040 M: 0.014	Train-SoftAcc=0.714550,	AnsLoss=2.746724,	
2020-11-17 15:23:27,739 Epoch[3] Batch [18100]	Speed: 64.33 samples/s ETA: 0 d  3 h 10 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.013	Train-SoftAcc=0.714666,	AnsLoss=2.746048,	
2020-11-17 15:24:17,102 Epoch[3] Batch [18200]	Speed: 64.83 samples/s ETA: 0 d  3 h  8 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.040 M: 0.014	Train-SoftAcc=0.714858,	AnsLoss=2.745199,	
2020-11-17 15:25:05,658 Epoch[3] Batch [18300]	Speed: 65.90 samples/s ETA: 0 d  3 h  4 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.395 O: 0.040 M: 0.013	Train-SoftAcc=0.715000,	AnsLoss=2.744174,	
2020-11-17 15:25:54,866 Epoch[3] Batch [18400]	Speed: 65.03 samples/s ETA: 0 d  3 h  6 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.014	Train-SoftAcc=0.715119,	AnsLoss=2.743557,	
2020-11-17 15:26:44,401 Epoch[3] Batch [18500]	Speed: 64.60 samples/s ETA: 0 d  3 h  6 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.039 M: 0.014	Train-SoftAcc=0.715252,	AnsLoss=2.742728,	
2020-11-17 15:27:33,262 Epoch[3] Batch [18600]	Speed: 65.49 samples/s ETA: 0 d  3 h  3 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.398 O: 0.040 M: 0.013	Train-SoftAcc=0.715298,	AnsLoss=2.742208,	
2020-11-17 15:28:22,791 Epoch[3] Batch [18700]	Speed: 64.61 samples/s ETA: 0 d  3 h  5 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.013	Train-SoftAcc=0.715380,	AnsLoss=2.741558,	
2020-11-17 15:29:12,714 Epoch[3] Batch [18800]	Speed: 64.10 samples/s ETA: 0 d  3 h  5 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.409 O: 0.040 M: 0.013	Train-SoftAcc=0.715418,	AnsLoss=2.741375,	
2020-11-17 15:30:02,637 Epoch[3] Batch [18900]	Speed: 64.10 samples/s ETA: 0 d  3 h  4 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.013	Train-SoftAcc=0.715486,	AnsLoss=2.740757,	
2020-11-17 15:30:51,608 Epoch[3] Batch [19000]	Speed: 65.35 samples/s ETA: 0 d  3 h  0 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.399 O: 0.040 M: 0.013	Train-SoftAcc=0.715580,	AnsLoss=2.740088,	
2020-11-17 15:31:42,006 Epoch[3] Batch [19100]	Speed: 63.50 samples/s ETA: 0 d  3 h  5 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.414 O: 0.039 M: 0.014	Train-SoftAcc=0.715610,	AnsLoss=2.740014,	
2020-11-17 15:32:31,662 Epoch[3] Batch [19200]	Speed: 64.44 samples/s ETA: 0 d  3 h  1 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.013	Train-SoftAcc=0.715689,	AnsLoss=2.739454,	
2020-11-17 15:33:21,370 Epoch[3] Batch [19300]	Speed: 64.38 samples/s ETA: 0 d  3 h  0 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.014	Train-SoftAcc=0.715734,	AnsLoss=2.739094,	
2020-11-17 15:34:11,173 Epoch[3] Batch [19400]	Speed: 64.25 samples/s ETA: 0 d  3 h  0 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.014	Train-SoftAcc=0.715766,	AnsLoss=2.738885,	
2020-11-17 15:35:00,974 Epoch[3] Batch [19500]	Speed: 64.26 samples/s ETA: 0 d  2 h 59 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.040 M: 0.014	Train-SoftAcc=0.715791,	AnsLoss=2.738668,	
2020-11-17 15:35:50,458 Epoch[3] Batch [19600]	Speed: 64.67 samples/s ETA: 0 d  2 h 57 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.405 O: 0.040 M: 0.014	Train-SoftAcc=0.715844,	AnsLoss=2.737944,	
2020-11-17 15:36:39,623 Epoch[3] Batch [19700]	Speed: 65.09 samples/s ETA: 0 d  2 h 55 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.401 O: 0.040 M: 0.013	Train-SoftAcc=0.715937,	AnsLoss=2.737264,	
2020-11-17 15:37:29,185 Epoch[3] Batch [19800]	Speed: 64.57 samples/s ETA: 0 d  2 h 56 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.013	Train-SoftAcc=0.715965,	AnsLoss=2.737092,	
2020-11-17 15:38:18,956 Epoch[3] Batch [19900]	Speed: 64.29 samples/s ETA: 0 d  2 h 56 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.040 M: 0.013	Train-SoftAcc=0.716055,	AnsLoss=2.736589,	
2020-11-17 15:39:08,441 Epoch[3] Batch [20000]	Speed: 64.71 samples/s ETA: 0 d  2 h 54 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.404 O: 0.040 M: 0.013	Train-SoftAcc=0.716124,	AnsLoss=2.735729,	
2020-11-17 15:39:57,842 Epoch[3] Batch [20100]	Speed: 64.78 samples/s ETA: 0 d  2 h 53 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.404 O: 0.039 M: 0.014	Train-SoftAcc=0.716159,	AnsLoss=2.735210,	
2020-11-17 15:40:47,737 Epoch[3] Batch [20200]	Speed: 64.14 samples/s ETA: 0 d  2 h 54 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.409 O: 0.040 M: 0.014	Train-SoftAcc=0.716263,	AnsLoss=2.734535,	
2020-11-17 15:41:37,226 Epoch[3] Batch [20300]	Speed: 64.66 samples/s ETA: 0 d  2 h 51 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.404 O: 0.040 M: 0.014	Train-SoftAcc=0.716274,	AnsLoss=2.734329,	
2020-11-17 15:42:26,324 Epoch[3] Batch [20400]	Speed: 65.18 samples/s ETA: 0 d  2 h 49 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.400 O: 0.040 M: 0.014	Train-SoftAcc=0.716383,	AnsLoss=2.733571,	
2020-11-17 15:43:16,530 Epoch[3] Batch [20500]	Speed: 63.74 samples/s ETA: 0 d  2 h 52 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.411 O: 0.040 M: 0.013	Train-SoftAcc=0.716489,	AnsLoss=2.733348,	
2020-11-17 16:00:45,124 New Best Val SoftAcc: 0.7381582260131836, Epoch: 3
2020-11-17 16:00:45,125 Epoch[3] 	Val-SoftAcc=0.738158,	
2020-11-17 16:00:45,125 Best Val SoftAcc: 0.7381582260131836, Epoch: 3
2020-11-17 16:01:16,901 Epoch[4] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-SoftAcc=0.728125,	AnsLoss=2.005131,	
2020-11-17 16:02:07,792 Epoch[4] Batch [100]	Speed: 62.88 samples/s ETA: 0 d  2 h 53 m	Data: 0.021 Tran: 0.007 F: 0.045 B: 0.682 O: 0.066 M: 0.022	Train-SoftAcc=0.740068,	AnsLoss=2.562239,	
2020-11-17 16:02:56,417 Epoch[4] Batch [200]	Speed: 65.85 samples/s ETA: 0 d  2 h 44 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.396 O: 0.039 M: 0.014	Train-SoftAcc=0.738790,	AnsLoss=2.582858,	
2020-11-17 16:03:45,812 Epoch[4] Batch [300]	Speed: 64.79 samples/s ETA: 0 d  2 h 46 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.040 M: 0.013	Train-SoftAcc=0.744965,	AnsLoss=2.557165,	
2020-11-17 16:04:35,108 Epoch[4] Batch [400]	Speed: 64.92 samples/s ETA: 0 d  2 h 45 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.014	Train-SoftAcc=0.746446,	AnsLoss=2.555168,	
2020-11-17 16:05:24,406 Epoch[4] Batch [500]	Speed: 64.91 samples/s ETA: 0 d  2 h 44 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.014	Train-SoftAcc=0.747262,	AnsLoss=2.546605,	
2020-11-17 16:06:13,705 Epoch[4] Batch [600]	Speed: 64.91 samples/s ETA: 0 d  2 h 44 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.014	Train-SoftAcc=0.746766,	AnsLoss=2.543152,	
2020-11-17 16:07:04,054 Epoch[4] Batch [700]	Speed: 63.56 samples/s ETA: 0 d  2 h 46 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.413 O: 0.040 M: 0.014	Train-SoftAcc=0.746675,	AnsLoss=2.544234,	
2020-11-17 16:07:53,672 Epoch[4] Batch [800]	Speed: 64.49 samples/s ETA: 0 d  2 h 43 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.014	Train-SoftAcc=0.746746,	AnsLoss=2.539025,	
2020-11-17 16:08:43,842 Epoch[4] Batch [900]	Speed: 63.78 samples/s ETA: 0 d  2 h 44 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.411 O: 0.040 M: 0.014	Train-SoftAcc=0.748464,	AnsLoss=2.536896,	
2020-11-17 16:09:33,830 Epoch[4] Batch [1000]	Speed: 64.02 samples/s ETA: 0 d  2 h 43 m	Data: 0.005 Tran: 0.005 F: 0.028 B: 0.409 O: 0.040 M: 0.013	Train-SoftAcc=0.748442,	AnsLoss=2.544899,	
2020-11-17 16:10:23,959 Epoch[4] Batch [1100]	Speed: 63.84 samples/s ETA: 0 d  2 h 42 m	Data: 0.005 Tran: 0.005 F: 0.026 B: 0.411 O: 0.039 M: 0.014	Train-SoftAcc=0.747755,	AnsLoss=2.545290,	
2020-11-17 16:11:14,057 Epoch[4] Batch [1200]	Speed: 63.88 samples/s ETA: 0 d  2 h 41 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.410 O: 0.040 M: 0.014	Train-SoftAcc=0.748634,	AnsLoss=2.540972,	
2020-11-17 16:12:03,691 Epoch[4] Batch [1300]	Speed: 64.47 samples/s ETA: 0 d  2 h 39 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.014	Train-SoftAcc=0.749003,	AnsLoss=2.541858,	
2020-11-17 16:12:53,407 Epoch[4] Batch [1400]	Speed: 64.37 samples/s ETA: 0 d  2 h 38 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.407 O: 0.039 M: 0.014	Train-SoftAcc=0.749650,	AnsLoss=2.539504,	
2020-11-17 16:13:42,572 Epoch[4] Batch [1500]	Speed: 65.09 samples/s ETA: 0 d  2 h 36 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.039 M: 0.014	Train-SoftAcc=0.749329,	AnsLoss=2.541761,	
2020-11-17 16:14:31,689 Epoch[4] Batch [1600]	Speed: 65.15 samples/s ETA: 0 d  2 h 35 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.400 O: 0.040 M: 0.014	Train-SoftAcc=0.749461,	AnsLoss=2.543211,	
2020-11-17 16:15:22,407 Epoch[4] Batch [1700]	Speed: 63.10 samples/s ETA: 0 d  2 h 39 m	Data: 0.005 Tran: 0.005 F: 0.028 B: 0.416 O: 0.040 M: 0.013	Train-SoftAcc=0.749078,	AnsLoss=2.543216,	
2020-11-17 16:16:11,525 Epoch[4] Batch [1800]	Speed: 65.15 samples/s ETA: 0 d  2 h 33 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.401 O: 0.040 M: 0.014	Train-SoftAcc=0.749313,	AnsLoss=2.546048,	
2020-11-17 16:17:01,255 Epoch[4] Batch [1900]	Speed: 64.35 samples/s ETA: 0 d  2 h 34 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.013	Train-SoftAcc=0.749686,	AnsLoss=2.542003,	
2020-11-17 16:17:50,904 Epoch[4] Batch [2000]	Speed: 64.45 samples/s ETA: 0 d  2 h 33 m	Data: 0.005 Tran: 0.004 F: 0.028 B: 0.405 O: 0.041 M: 0.013	Train-SoftAcc=0.749563,	AnsLoss=2.541973,	
2020-11-17 16:18:41,346 Epoch[4] Batch [2100]	Speed: 63.44 samples/s ETA: 0 d  2 h 35 m	Data: 0.005 Tran: 0.005 F: 0.028 B: 0.413 O: 0.040 M: 0.013	Train-SoftAcc=0.749875,	AnsLoss=2.543044,	
2020-11-17 16:19:30,677 Epoch[4] Batch [2200]	Speed: 64.87 samples/s ETA: 0 d  2 h 30 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.014	Train-SoftAcc=0.750335,	AnsLoss=2.541664,	
2020-11-17 16:20:20,554 Epoch[4] Batch [2300]	Speed: 64.16 samples/s ETA: 0 d  2 h 31 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.014	Train-SoftAcc=0.749851,	AnsLoss=2.541106,	
2020-11-17 16:21:10,142 Epoch[4] Batch [2400]	Speed: 64.53 samples/s ETA: 0 d  2 h 30 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.014	Train-SoftAcc=0.749299,	AnsLoss=2.542446,	
2020-11-17 16:21:59,863 Epoch[4] Batch [2500]	Speed: 64.36 samples/s ETA: 0 d  2 h 29 m	Data: 0.005 Tran: 0.005 F: 0.028 B: 0.405 O: 0.040 M: 0.014	Train-SoftAcc=0.748998,	AnsLoss=2.543283,	
2020-11-17 16:22:49,099 Epoch[4] Batch [2600]	Speed: 65.00 samples/s ETA: 0 d  2 h 27 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.401 O: 0.040 M: 0.013	Train-SoftAcc=0.749379,	AnsLoss=2.542058,	
2020-11-17 16:23:38,069 Epoch[4] Batch [2700]	Speed: 65.35 samples/s ETA: 0 d  2 h 25 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.400 O: 0.039 M: 0.014	Train-SoftAcc=0.749442,	AnsLoss=2.541628,	
2020-11-17 16:24:27,188 Epoch[4] Batch [2800]	Speed: 65.15 samples/s ETA: 0 d  2 h 25 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.401 O: 0.040 M: 0.014	Train-SoftAcc=0.748993,	AnsLoss=2.545422,	
2020-11-17 16:25:16,203 Epoch[4] Batch [2900]	Speed: 65.29 samples/s ETA: 0 d  2 h 24 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.400 O: 0.040 M: 0.013	Train-SoftAcc=0.749160,	AnsLoss=2.546473,	
2020-11-17 16:26:05,683 Epoch[4] Batch [3000]	Speed: 64.67 samples/s ETA: 0 d  2 h 24 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.404 O: 0.040 M: 0.014	Train-SoftAcc=0.748696,	AnsLoss=2.548446,	
2020-11-17 16:26:55,130 Epoch[4] Batch [3100]	Speed: 64.72 samples/s ETA: 0 d  2 h 23 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.404 O: 0.040 M: 0.014	Train-SoftAcc=0.748816,	AnsLoss=2.551005,	
2020-11-17 16:27:45,243 Epoch[4] Batch [3200]	Speed: 63.86 samples/s ETA: 0 d  2 h 25 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.410 O: 0.040 M: 0.013	Train-SoftAcc=0.749039,	AnsLoss=2.551769,	
2020-11-17 16:28:35,455 Epoch[4] Batch [3300]	Speed: 63.73 samples/s ETA: 0 d  2 h 24 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.412 O: 0.040 M: 0.014	Train-SoftAcc=0.748372,	AnsLoss=2.553611,	
2020-11-17 16:29:25,432 Epoch[4] Batch [3400]	Speed: 64.03 samples/s ETA: 0 d  2 h 22 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.410 O: 0.040 M: 0.014	Train-SoftAcc=0.748558,	AnsLoss=2.552979,	
2020-11-17 16:30:14,949 Epoch[4] Batch [3500]	Speed: 64.63 samples/s ETA: 0 d  2 h 20 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.405 O: 0.039 M: 0.014	Train-SoftAcc=0.748289,	AnsLoss=2.553297,	
2020-11-17 16:31:05,080 Epoch[4] Batch [3600]	Speed: 63.89 samples/s ETA: 0 d  2 h 21 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.410 O: 0.040 M: 0.014	Train-SoftAcc=0.748401,	AnsLoss=2.551236,	
2020-11-17 16:31:54,919 Epoch[4] Batch [3700]	Speed: 64.21 samples/s ETA: 0 d  2 h 20 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.014	Train-SoftAcc=0.748269,	AnsLoss=2.552271,	
2020-11-17 16:32:45,191 Epoch[4] Batch [3800]	Speed: 63.66 samples/s ETA: 0 d  2 h 20 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.412 O: 0.040 M: 0.014	Train-SoftAcc=0.748145,	AnsLoss=2.551580,	
2020-11-17 16:33:35,426 Epoch[4] Batch [3900]	Speed: 63.70 samples/s ETA: 0 d  2 h 19 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.412 O: 0.040 M: 0.013	Train-SoftAcc=0.748083,	AnsLoss=2.552170,	
2020-11-17 16:34:24,554 Epoch[4] Batch [4000]	Speed: 65.14 samples/s ETA: 0 d  2 h 15 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.401 O: 0.040 M: 0.013	Train-SoftAcc=0.747726,	AnsLoss=2.553897,	
2020-11-17 16:35:14,923 Epoch[4] Batch [4100]	Speed: 63.53 samples/s ETA: 0 d  2 h 18 m	Data: 0.005 Tran: 0.005 F: 0.028 B: 0.412 O: 0.040 M: 0.013	Train-SoftAcc=0.748014,	AnsLoss=2.552665,	
2020-11-17 16:36:04,930 Epoch[4] Batch [4200]	Speed: 63.99 samples/s ETA: 0 d  2 h 16 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.409 O: 0.040 M: 0.013	Train-SoftAcc=0.748221,	AnsLoss=2.551245,	
2020-11-17 16:36:54,448 Epoch[4] Batch [4300]	Speed: 64.63 samples/s ETA: 0 d  2 h 14 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.404 O: 0.040 M: 0.014	Train-SoftAcc=0.748273,	AnsLoss=2.551529,	
2020-11-17 16:37:43,877 Epoch[4] Batch [4400]	Speed: 64.74 samples/s ETA: 0 d  2 h 13 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.404 O: 0.040 M: 0.013	Train-SoftAcc=0.748242,	AnsLoss=2.552079,	
2020-11-17 16:38:33,408 Epoch[4] Batch [4500]	Speed: 64.61 samples/s ETA: 0 d  2 h 12 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.014	Train-SoftAcc=0.748367,	AnsLoss=2.550383,	
2020-11-17 16:39:22,939 Epoch[4] Batch [4600]	Speed: 64.61 samples/s ETA: 0 d  2 h 11 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.013	Train-SoftAcc=0.748392,	AnsLoss=2.550430,	
2020-11-17 16:40:12,692 Epoch[4] Batch [4700]	Speed: 64.32 samples/s ETA: 0 d  2 h 11 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.040 M: 0.014	Train-SoftAcc=0.748207,	AnsLoss=2.552001,	
2020-11-17 16:41:01,994 Epoch[4] Batch [4800]	Speed: 64.91 samples/s ETA: 0 d  2 h  9 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.040 M: 0.013	Train-SoftAcc=0.748205,	AnsLoss=2.550258,	
2020-11-17 16:41:52,277 Epoch[4] Batch [4900]	Speed: 63.64 samples/s ETA: 0 d  2 h 11 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.412 O: 0.040 M: 0.013	Train-SoftAcc=0.748005,	AnsLoss=2.550800,	
2020-11-17 16:42:42,398 Epoch[4] Batch [5000]	Speed: 63.85 samples/s ETA: 0 d  2 h 10 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.411 O: 0.040 M: 0.014	Train-SoftAcc=0.748045,	AnsLoss=2.551325,	
2020-11-17 16:43:32,695 Epoch[4] Batch [5100]	Speed: 63.62 samples/s ETA: 0 d  2 h  9 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.412 O: 0.040 M: 0.013	Train-SoftAcc=0.747992,	AnsLoss=2.550537,	
2020-11-17 16:44:22,216 Epoch[4] Batch [5200]	Speed: 64.62 samples/s ETA: 0 d  2 h  6 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.404 O: 0.040 M: 0.013	Train-SoftAcc=0.747965,	AnsLoss=2.551198,	
2020-11-17 16:45:11,852 Epoch[4] Batch [5300]	Speed: 64.47 samples/s ETA: 0 d  2 h  6 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.014	Train-SoftAcc=0.748057,	AnsLoss=2.550682,	
2020-11-17 16:46:00,632 Epoch[4] Batch [5400]	Speed: 65.60 samples/s ETA: 0 d  2 h  3 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.397 O: 0.040 M: 0.014	Train-SoftAcc=0.747877,	AnsLoss=2.551146,	
2020-11-17 16:46:50,180 Epoch[4] Batch [5500]	Speed: 64.58 samples/s ETA: 0 d  2 h  4 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.406 O: 0.039 M: 0.014	Train-SoftAcc=0.747800,	AnsLoss=2.551547,	
2020-11-17 16:47:39,516 Epoch[4] Batch [5600]	Speed: 64.86 samples/s ETA: 0 d  2 h  3 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.040 M: 0.013	Train-SoftAcc=0.747675,	AnsLoss=2.552008,	
2020-11-17 16:48:29,518 Epoch[4] Batch [5700]	Speed: 64.00 samples/s ETA: 0 d  2 h  3 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.410 O: 0.039 M: 0.014	Train-SoftAcc=0.747795,	AnsLoss=2.552120,	
2020-11-17 16:49:18,811 Epoch[4] Batch [5800]	Speed: 64.96 samples/s ETA: 0 d  2 h  1 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.013	Train-SoftAcc=0.747840,	AnsLoss=2.553756,	
2020-11-17 16:50:07,415 Epoch[4] Batch [5900]	Speed: 65.84 samples/s ETA: 0 d  1 h 58 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.396 O: 0.039 M: 0.014	Train-SoftAcc=0.747865,	AnsLoss=2.554356,	
2020-11-17 16:50:56,183 Epoch[4] Batch [6000]	Speed: 65.62 samples/s ETA: 0 d  1 h 58 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.397 O: 0.040 M: 0.014	Train-SoftAcc=0.747991,	AnsLoss=2.553469,	
2020-11-17 16:51:45,363 Epoch[4] Batch [6100]	Speed: 65.07 samples/s ETA: 0 d  1 h 58 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.014	Train-SoftAcc=0.747814,	AnsLoss=2.554833,	
2020-11-17 16:52:34,084 Epoch[4] Batch [6200]	Speed: 65.68 samples/s ETA: 0 d  1 h 56 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.397 O: 0.039 M: 0.014	Train-SoftAcc=0.747857,	AnsLoss=2.554477,	
2020-11-17 16:53:23,827 Epoch[4] Batch [6300]	Speed: 64.33 samples/s ETA: 0 d  1 h 58 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.040 M: 0.013	Train-SoftAcc=0.747738,	AnsLoss=2.555019,	
2020-11-17 16:54:13,468 Epoch[4] Batch [6400]	Speed: 64.46 samples/s ETA: 0 d  1 h 57 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.013	Train-SoftAcc=0.747814,	AnsLoss=2.554770,	
2020-11-17 16:55:02,794 Epoch[4] Batch [6500]	Speed: 64.88 samples/s ETA: 0 d  1 h 55 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.040 M: 0.013	Train-SoftAcc=0.747842,	AnsLoss=2.554193,	
2020-11-17 16:55:52,588 Epoch[4] Batch [6600]	Speed: 64.27 samples/s ETA: 0 d  1 h 55 m	Data: 0.005 Tran: 0.004 F: 0.029 B: 0.406 O: 0.040 M: 0.014	Train-SoftAcc=0.747607,	AnsLoss=2.555945,	
2020-11-17 16:56:42,144 Epoch[4] Batch [6700]	Speed: 64.58 samples/s ETA: 0 d  1 h 54 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.013	Train-SoftAcc=0.747523,	AnsLoss=2.556277,	
2020-11-17 16:57:31,883 Epoch[4] Batch [6800]	Speed: 64.34 samples/s ETA: 0 d  1 h 54 m	Data: 0.005 Tran: 0.005 F: 0.028 B: 0.405 O: 0.041 M: 0.013	Train-SoftAcc=0.747569,	AnsLoss=2.555365,	
2020-11-17 16:58:20,372 Epoch[4] Batch [6900]	Speed: 66.00 samples/s ETA: 0 d  1 h 50 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.394 O: 0.040 M: 0.014	Train-SoftAcc=0.747579,	AnsLoss=2.556580,	
2020-11-17 16:59:10,019 Epoch[4] Batch [7000]	Speed: 64.46 samples/s ETA: 0 d  1 h 52 m	Data: 0.005 Tran: 0.005 F: 0.028 B: 0.405 O: 0.041 M: 0.013	Train-SoftAcc=0.747597,	AnsLoss=2.556104,	
2020-11-17 16:59:59,951 Epoch[4] Batch [7100]	Speed: 64.09 samples/s ETA: 0 d  1 h 52 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.409 O: 0.040 M: 0.014	Train-SoftAcc=0.747650,	AnsLoss=2.555537,	
2020-11-17 17:00:50,158 Epoch[4] Batch [7200]	Speed: 63.74 samples/s ETA: 0 d  1 h 51 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.411 O: 0.040 M: 0.013	Train-SoftAcc=0.747687,	AnsLoss=2.555725,	
2020-11-17 17:01:40,334 Epoch[4] Batch [7300]	Speed: 63.78 samples/s ETA: 0 d  1 h 50 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.411 O: 0.040 M: 0.013	Train-SoftAcc=0.747868,	AnsLoss=2.556793,	
2020-11-17 17:02:30,249 Epoch[4] Batch [7400]	Speed: 64.11 samples/s ETA: 0 d  1 h 49 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.013	Train-SoftAcc=0.747882,	AnsLoss=2.557111,	
2020-11-17 17:03:19,611 Epoch[4] Batch [7500]	Speed: 64.83 samples/s ETA: 0 d  1 h 47 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.040 M: 0.014	Train-SoftAcc=0.747749,	AnsLoss=2.557655,	
2020-11-17 17:04:09,270 Epoch[4] Batch [7600]	Speed: 64.44 samples/s ETA: 0 d  1 h 47 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.014	Train-SoftAcc=0.747683,	AnsLoss=2.558356,	
2020-11-17 17:04:59,667 Epoch[4] Batch [7700]	Speed: 63.50 samples/s ETA: 0 d  1 h 48 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.413 O: 0.040 M: 0.013	Train-SoftAcc=0.747679,	AnsLoss=2.559035,	
2020-11-17 17:05:49,994 Epoch[4] Batch [7800]	Speed: 63.59 samples/s ETA: 0 d  1 h 47 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.412 O: 0.040 M: 0.013	Train-SoftAcc=0.747414,	AnsLoss=2.559302,	
2020-11-17 17:06:39,703 Epoch[4] Batch [7900]	Speed: 64.45 samples/s ETA: 0 d  1 h 44 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.014	Train-SoftAcc=0.747474,	AnsLoss=2.558956,	
2020-11-17 17:07:29,248 Epoch[4] Batch [8000]	Speed: 64.59 samples/s ETA: 0 d  1 h 43 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.013	Train-SoftAcc=0.747605,	AnsLoss=2.558562,	
2020-11-17 17:08:19,083 Epoch[4] Batch [8100]	Speed: 64.21 samples/s ETA: 0 d  1 h 43 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.013	Train-SoftAcc=0.747636,	AnsLoss=2.559640,	
2020-11-17 17:09:08,272 Epoch[4] Batch [8200]	Speed: 65.06 samples/s ETA: 0 d  1 h 41 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.401 O: 0.040 M: 0.014	Train-SoftAcc=0.747568,	AnsLoss=2.559416,	
2020-11-17 17:09:57,684 Epoch[4] Batch [8300]	Speed: 64.76 samples/s ETA: 0 d  1 h 41 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.404 O: 0.039 M: 0.014	Train-SoftAcc=0.747547,	AnsLoss=2.559108,	
2020-11-17 17:10:46,411 Epoch[4] Batch [8400]	Speed: 65.67 samples/s ETA: 0 d  1 h 38 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.397 O: 0.040 M: 0.014	Train-SoftAcc=0.747554,	AnsLoss=2.558689,	
2020-11-17 17:11:35,976 Epoch[4] Batch [8500]	Speed: 64.56 samples/s ETA: 0 d  1 h 39 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.405 O: 0.040 M: 0.013	Train-SoftAcc=0.747490,	AnsLoss=2.558849,	
2020-11-17 17:12:25,704 Epoch[4] Batch [8600]	Speed: 64.35 samples/s ETA: 0 d  1 h 39 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.039 M: 0.014	Train-SoftAcc=0.747451,	AnsLoss=2.559031,	
2020-11-17 17:13:15,755 Epoch[4] Batch [8700]	Speed: 63.94 samples/s ETA: 0 d  1 h 38 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.410 O: 0.039 M: 0.014	Train-SoftAcc=0.747281,	AnsLoss=2.560084,	
2020-11-17 17:14:05,827 Epoch[4] Batch [8800]	Speed: 63.91 samples/s ETA: 0 d  1 h 38 m	Data: 0.005 Tran: 0.005 F: 0.028 B: 0.409 O: 0.040 M: 0.014	Train-SoftAcc=0.747111,	AnsLoss=2.561459,	
2020-11-17 17:14:55,881 Epoch[4] Batch [8900]	Speed: 63.93 samples/s ETA: 0 d  1 h 37 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.410 O: 0.040 M: 0.014	Train-SoftAcc=0.747113,	AnsLoss=2.560970,	
2020-11-17 17:15:45,443 Epoch[4] Batch [9000]	Speed: 64.57 samples/s ETA: 0 d  1 h 35 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.406 O: 0.039 M: 0.014	Train-SoftAcc=0.747056,	AnsLoss=2.561043,	
2020-11-17 17:16:35,152 Epoch[4] Batch [9100]	Speed: 64.38 samples/s ETA: 0 d  1 h 34 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.407 O: 0.039 M: 0.014	Train-SoftAcc=0.747047,	AnsLoss=2.561065,	
2020-11-17 17:17:25,014 Epoch[4] Batch [9200]	Speed: 64.18 samples/s ETA: 0 d  1 h 34 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.014	Train-SoftAcc=0.746976,	AnsLoss=2.561258,	
2020-11-17 17:18:15,031 Epoch[4] Batch [9300]	Speed: 63.98 samples/s ETA: 0 d  1 h 33 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.409 O: 0.040 M: 0.014	Train-SoftAcc=0.746926,	AnsLoss=2.561602,	
2020-11-17 17:19:04,613 Epoch[4] Batch [9400]	Speed: 64.54 samples/s ETA: 0 d  1 h 32 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.406 O: 0.040 M: 0.014	Train-SoftAcc=0.746934,	AnsLoss=2.561403,	
2020-11-17 17:19:54,001 Epoch[4] Batch [9500]	Speed: 64.79 samples/s ETA: 0 d  1 h 31 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.040 M: 0.013	Train-SoftAcc=0.746725,	AnsLoss=2.561989,	
2020-11-17 17:20:44,162 Epoch[4] Batch [9600]	Speed: 63.80 samples/s ETA: 0 d  1 h 31 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.411 O: 0.040 M: 0.014	Train-SoftAcc=0.746913,	AnsLoss=2.561350,	
2020-11-17 17:21:33,470 Epoch[4] Batch [9700]	Speed: 64.90 samples/s ETA: 0 d  1 h 29 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.403 O: 0.039 M: 0.014	Train-SoftAcc=0.746813,	AnsLoss=2.561218,	
2020-11-17 17:22:22,433 Epoch[4] Batch [9800]	Speed: 65.36 samples/s ETA: 0 d  1 h 27 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.399 O: 0.040 M: 0.014	Train-SoftAcc=0.746962,	AnsLoss=2.560834,	
2020-11-17 17:23:11,366 Epoch[4] Batch [9900]	Speed: 65.40 samples/s ETA: 0 d  1 h 26 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.399 O: 0.039 M: 0.014	Train-SoftAcc=0.746948,	AnsLoss=2.560665,	
2020-11-17 17:24:01,667 Epoch[4] Batch [10000]	Speed: 63.62 samples/s ETA: 0 d  1 h 28 m	Data: 0.005 Tran: 0.005 F: 0.028 B: 0.411 O: 0.040 M: 0.013	Train-SoftAcc=0.746884,	AnsLoss=2.561122,	
2020-11-17 17:24:51,028 Epoch[4] Batch [10100]	Speed: 64.83 samples/s ETA: 0 d  1 h 26 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.013	Train-SoftAcc=0.746791,	AnsLoss=2.561122,	
2020-11-17 17:25:40,066 Epoch[4] Batch [10200]	Speed: 65.26 samples/s ETA: 0 d  1 h 24 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.400 O: 0.040 M: 0.014	Train-SoftAcc=0.746817,	AnsLoss=2.561466,	
2020-11-17 17:26:29,488 Epoch[4] Batch [10300]	Speed: 64.75 samples/s ETA: 0 d  1 h 24 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.404 O: 0.040 M: 0.014	Train-SoftAcc=0.746895,	AnsLoss=2.561485,	
2020-11-17 17:27:19,230 Epoch[4] Batch [10400]	Speed: 64.33 samples/s ETA: 0 d  1 h 24 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.040 M: 0.014	Train-SoftAcc=0.746916,	AnsLoss=2.561330,	
2020-11-17 17:28:08,508 Epoch[4] Batch [10500]	Speed: 64.94 samples/s ETA: 0 d  1 h 22 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.014	Train-SoftAcc=0.746952,	AnsLoss=2.561493,	
2020-11-17 17:28:57,656 Epoch[4] Batch [10600]	Speed: 65.11 samples/s ETA: 0 d  1 h 21 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.401 O: 0.040 M: 0.013	Train-SoftAcc=0.746859,	AnsLoss=2.561741,	
2020-11-17 17:29:47,094 Epoch[4] Batch [10700]	Speed: 64.73 samples/s ETA: 0 d  1 h 21 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.404 O: 0.040 M: 0.014	Train-SoftAcc=0.746830,	AnsLoss=2.561144,	
2020-11-17 17:30:37,618 Epoch[4] Batch [10800]	Speed: 63.34 samples/s ETA: 0 d  1 h 22 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.414 O: 0.040 M: 0.013	Train-SoftAcc=0.746724,	AnsLoss=2.562380,	
2020-11-17 17:31:26,959 Epoch[4] Batch [10900]	Speed: 64.86 samples/s ETA: 0 d  1 h 19 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.039 M: 0.014	Train-SoftAcc=0.746688,	AnsLoss=2.562541,	
2020-11-17 17:32:16,584 Epoch[4] Batch [11000]	Speed: 64.48 samples/s ETA: 0 d  1 h 19 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.014	Train-SoftAcc=0.746610,	AnsLoss=2.562463,	
2020-11-17 17:33:05,870 Epoch[4] Batch [11100]	Speed: 64.93 samples/s ETA: 0 d  1 h 17 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.403 O: 0.039 M: 0.014	Train-SoftAcc=0.746570,	AnsLoss=2.562358,	
2020-11-17 17:33:56,080 Epoch[4] Batch [11200]	Speed: 63.73 samples/s ETA: 0 d  1 h 18 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.412 O: 0.039 M: 0.014	Train-SoftAcc=0.746686,	AnsLoss=2.561632,	
2020-11-17 17:34:45,260 Epoch[4] Batch [11300]	Speed: 65.07 samples/s ETA: 0 d  1 h 15 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.401 O: 0.040 M: 0.014	Train-SoftAcc=0.746687,	AnsLoss=2.562184,	
2020-11-17 17:35:34,988 Epoch[4] Batch [11400]	Speed: 64.35 samples/s ETA: 0 d  1 h 15 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.039 M: 0.014	Train-SoftAcc=0.746655,	AnsLoss=2.562476,	
2020-11-17 17:36:24,837 Epoch[4] Batch [11500]	Speed: 64.20 samples/s ETA: 0 d  1 h 15 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.039 M: 0.014	Train-SoftAcc=0.746718,	AnsLoss=2.562454,	
2020-11-17 17:37:15,067 Epoch[4] Batch [11600]	Speed: 63.71 samples/s ETA: 0 d  1 h 15 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.412 O: 0.039 M: 0.014	Train-SoftAcc=0.746663,	AnsLoss=2.563283,	
2020-11-17 17:38:04,424 Epoch[4] Batch [11700]	Speed: 64.83 samples/s ETA: 0 d  1 h 12 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.040 M: 0.013	Train-SoftAcc=0.746563,	AnsLoss=2.563383,	
2020-11-17 17:38:53,629 Epoch[4] Batch [11800]	Speed: 65.04 samples/s ETA: 0 d  1 h 11 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.402 O: 0.039 M: 0.014	Train-SoftAcc=0.746496,	AnsLoss=2.563322,	
2020-11-17 17:39:43,297 Epoch[4] Batch [11900]	Speed: 64.43 samples/s ETA: 0 d  1 h 11 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.039 M: 0.014	Train-SoftAcc=0.746453,	AnsLoss=2.563492,	
2020-11-17 17:40:33,106 Epoch[4] Batch [12000]	Speed: 64.25 samples/s ETA: 0 d  1 h 11 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.407 O: 0.040 M: 0.014	Train-SoftAcc=0.746401,	AnsLoss=2.563792,	
2020-11-17 17:41:22,671 Epoch[4] Batch [12100]	Speed: 64.56 samples/s ETA: 0 d  1 h  9 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.039 M: 0.014	Train-SoftAcc=0.746471,	AnsLoss=2.562969,	
2020-11-17 17:42:13,014 Epoch[4] Batch [12200]	Speed: 63.57 samples/s ETA: 0 d  1 h 10 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.413 O: 0.039 M: 0.014	Train-SoftAcc=0.746361,	AnsLoss=2.562968,	
2020-11-17 17:43:02,053 Epoch[4] Batch [12300]	Speed: 65.25 samples/s ETA: 0 d  1 h  7 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.400 O: 0.039 M: 0.014	Train-SoftAcc=0.746293,	AnsLoss=2.562546,	
2020-11-17 17:43:51,567 Epoch[4] Batch [12400]	Speed: 64.63 samples/s ETA: 0 d  1 h  7 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.014	Train-SoftAcc=0.746189,	AnsLoss=2.563548,	
2020-11-17 17:44:40,401 Epoch[4] Batch [12500]	Speed: 65.53 samples/s ETA: 0 d  1 h  5 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.398 O: 0.040 M: 0.014	Train-SoftAcc=0.746209,	AnsLoss=2.563632,	
2020-11-17 17:45:30,205 Epoch[4] Batch [12600]	Speed: 64.25 samples/s ETA: 0 d  1 h  6 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.040 M: 0.013	Train-SoftAcc=0.746258,	AnsLoss=2.563574,	
2020-11-17 17:46:20,222 Epoch[4] Batch [12700]	Speed: 63.98 samples/s ETA: 0 d  1 h  5 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.410 O: 0.040 M: 0.014	Train-SoftAcc=0.746144,	AnsLoss=2.563638,	
2020-11-17 17:47:10,499 Epoch[4] Batch [12800]	Speed: 63.65 samples/s ETA: 0 d  1 h  5 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.412 O: 0.040 M: 0.014	Train-SoftAcc=0.746189,	AnsLoss=2.563137,	
2020-11-17 17:47:59,718 Epoch[4] Batch [12900]	Speed: 65.02 samples/s ETA: 0 d  1 h  2 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.013	Train-SoftAcc=0.746212,	AnsLoss=2.563578,	
2020-11-17 17:48:49,048 Epoch[4] Batch [13000]	Speed: 64.87 samples/s ETA: 0 d  1 h  2 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.040 M: 0.014	Train-SoftAcc=0.746206,	AnsLoss=2.563200,	
2020-11-17 17:49:39,128 Epoch[4] Batch [13100]	Speed: 63.90 samples/s ETA: 0 d  1 h  2 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.409 O: 0.040 M: 0.014	Train-SoftAcc=0.746160,	AnsLoss=2.563369,	
2020-11-17 17:50:29,304 Epoch[4] Batch [13200]	Speed: 63.78 samples/s ETA: 0 d  1 h  1 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.411 O: 0.040 M: 0.013	Train-SoftAcc=0.746172,	AnsLoss=2.563446,	
2020-11-17 17:51:18,300 Epoch[4] Batch [13300]	Speed: 65.31 samples/s ETA: 0 d  0 h 59 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.399 O: 0.041 M: 0.013	Train-SoftAcc=0.746272,	AnsLoss=2.563047,	
2020-11-17 17:52:07,330 Epoch[4] Batch [13400]	Speed: 65.27 samples/s ETA: 0 d  0 h 58 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.399 O: 0.041 M: 0.013	Train-SoftAcc=0.746241,	AnsLoss=2.563629,	
2020-11-17 17:52:56,826 Epoch[4] Batch [13500]	Speed: 64.65 samples/s ETA: 0 d  0 h 58 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.404 O: 0.040 M: 0.014	Train-SoftAcc=0.746193,	AnsLoss=2.563523,	
2020-11-17 17:53:46,011 Epoch[4] Batch [13600]	Speed: 65.06 samples/s ETA: 0 d  0 h 57 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.401 O: 0.040 M: 0.014	Train-SoftAcc=0.746134,	AnsLoss=2.563739,	
2020-11-17 17:54:35,960 Epoch[4] Batch [13700]	Speed: 64.07 samples/s ETA: 0 d  0 h 57 m	Data: 0.005 Tran: 0.005 F: 0.028 B: 0.407 O: 0.040 M: 0.013	Train-SoftAcc=0.746152,	AnsLoss=2.563834,	
2020-11-17 17:55:25,037 Epoch[4] Batch [13800]	Speed: 65.20 samples/s ETA: 0 d  0 h 55 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.400 O: 0.040 M: 0.014	Train-SoftAcc=0.746175,	AnsLoss=2.563963,	
2020-11-17 17:56:13,985 Epoch[4] Batch [13900]	Speed: 65.38 samples/s ETA: 0 d  0 h 54 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.399 O: 0.040 M: 0.014	Train-SoftAcc=0.746225,	AnsLoss=2.563820,	
2020-11-17 17:57:03,573 Epoch[4] Batch [14000]	Speed: 64.53 samples/s ETA: 0 d  0 h 54 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.013	Train-SoftAcc=0.746165,	AnsLoss=2.564438,	
2020-11-17 17:57:52,918 Epoch[4] Batch [14100]	Speed: 64.85 samples/s ETA: 0 d  0 h 53 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.040 M: 0.014	Train-SoftAcc=0.746088,	AnsLoss=2.564967,	
2020-11-17 17:58:42,491 Epoch[4] Batch [14200]	Speed: 64.55 samples/s ETA: 0 d  0 h 52 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.014	Train-SoftAcc=0.746138,	AnsLoss=2.564311,	
2020-11-17 17:59:32,157 Epoch[4] Batch [14300]	Speed: 64.43 samples/s ETA: 0 d  0 h 51 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.014	Train-SoftAcc=0.746072,	AnsLoss=2.564639,	
2020-11-17 18:00:22,396 Epoch[4] Batch [14400]	Speed: 63.70 samples/s ETA: 0 d  0 h 51 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.411 O: 0.040 M: 0.014	Train-SoftAcc=0.746070,	AnsLoss=2.565218,	
2020-11-17 18:01:12,044 Epoch[4] Batch [14500]	Speed: 64.46 samples/s ETA: 0 d  0 h 50 m	Data: 0.005 Tran: 0.005 F: 0.028 B: 0.405 O: 0.041 M: 0.013	Train-SoftAcc=0.746010,	AnsLoss=2.565521,	
2020-11-17 18:02:01,709 Epoch[4] Batch [14600]	Speed: 64.43 samples/s ETA: 0 d  0 h 49 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.013	Train-SoftAcc=0.745880,	AnsLoss=2.565961,	
2020-11-17 18:02:50,970 Epoch[4] Batch [14700]	Speed: 64.96 samples/s ETA: 0 d  0 h 48 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.013	Train-SoftAcc=0.745886,	AnsLoss=2.565645,	
2020-11-17 18:03:40,247 Epoch[4] Batch [14800]	Speed: 64.94 samples/s ETA: 0 d  0 h 47 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.014	Train-SoftAcc=0.745842,	AnsLoss=2.565571,	
2020-11-17 18:04:29,561 Epoch[4] Batch [14900]	Speed: 64.89 samples/s ETA: 0 d  0 h 46 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.014	Train-SoftAcc=0.745933,	AnsLoss=2.565187,	
2020-11-17 18:05:18,878 Epoch[4] Batch [15000]	Speed: 64.89 samples/s ETA: 0 d  0 h 45 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.014	Train-SoftAcc=0.745916,	AnsLoss=2.565241,	
2020-11-17 18:06:08,671 Epoch[4] Batch [15100]	Speed: 64.27 samples/s ETA: 0 d  0 h 45 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.040 M: 0.014	Train-SoftAcc=0.745847,	AnsLoss=2.565504,	
2020-11-17 18:06:58,125 Epoch[4] Batch [15200]	Speed: 64.71 samples/s ETA: 0 d  0 h 44 m	Data: 0.005 Tran: 0.004 F: 0.028 B: 0.403 O: 0.040 M: 0.013	Train-SoftAcc=0.745834,	AnsLoss=2.565177,	
2020-11-17 18:07:47,324 Epoch[4] Batch [15300]	Speed: 65.04 samples/s ETA: 0 d  0 h 43 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.401 O: 0.040 M: 0.014	Train-SoftAcc=0.745735,	AnsLoss=2.565557,	
2020-11-17 18:08:37,016 Epoch[4] Batch [15400]	Speed: 64.40 samples/s ETA: 0 d  0 h 42 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.040 M: 0.014	Train-SoftAcc=0.745742,	AnsLoss=2.565723,	
2020-11-17 18:09:27,508 Epoch[4] Batch [15500]	Speed: 63.38 samples/s ETA: 0 d  0 h 42 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.414 O: 0.040 M: 0.013	Train-SoftAcc=0.745716,	AnsLoss=2.566379,	
2020-11-17 18:10:17,365 Epoch[4] Batch [15600]	Speed: 64.19 samples/s ETA: 0 d  0 h 41 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.407 O: 0.041 M: 0.013	Train-SoftAcc=0.745758,	AnsLoss=2.566864,	
2020-11-17 18:11:06,762 Epoch[4] Batch [15700]	Speed: 64.78 samples/s ETA: 0 d  0 h 40 m	Data: 0.005 Tran: 0.004 F: 0.028 B: 0.403 O: 0.041 M: 0.013	Train-SoftAcc=0.745780,	AnsLoss=2.566572,	
2020-11-17 18:11:56,140 Epoch[4] Batch [15800]	Speed: 64.81 samples/s ETA: 0 d  0 h 39 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.403 O: 0.040 M: 0.014	Train-SoftAcc=0.745778,	AnsLoss=2.566510,	
2020-11-17 18:12:45,473 Epoch[4] Batch [15900]	Speed: 64.87 samples/s ETA: 0 d  0 h 38 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.014	Train-SoftAcc=0.745801,	AnsLoss=2.566285,	
2020-11-17 18:13:35,286 Epoch[4] Batch [16000]	Speed: 64.24 samples/s ETA: 0 d  0 h 37 m	Data: 0.005 Tran: 0.005 F: 0.028 B: 0.406 O: 0.040 M: 0.013	Train-SoftAcc=0.745791,	AnsLoss=2.566603,	
2020-11-17 18:14:25,276 Epoch[4] Batch [16100]	Speed: 64.01 samples/s ETA: 0 d  0 h 37 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.409 O: 0.040 M: 0.013	Train-SoftAcc=0.745768,	AnsLoss=2.567010,	
2020-11-17 18:15:15,488 Epoch[4] Batch [16200]	Speed: 63.73 samples/s ETA: 0 d  0 h 36 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.411 O: 0.040 M: 0.013	Train-SoftAcc=0.745862,	AnsLoss=2.566443,	
2020-11-17 18:16:05,756 Epoch[4] Batch [16300]	Speed: 63.66 samples/s ETA: 0 d  0 h 35 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.412 O: 0.040 M: 0.013	Train-SoftAcc=0.745813,	AnsLoss=2.566783,	
2020-11-17 18:16:55,446 Epoch[4] Batch [16400]	Speed: 64.40 samples/s ETA: 0 d  0 h 34 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.014	Train-SoftAcc=0.745741,	AnsLoss=2.567313,	
2020-11-17 18:17:45,278 Epoch[4] Batch [16500]	Speed: 64.22 samples/s ETA: 0 d  0 h 33 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.040 M: 0.013	Train-SoftAcc=0.745754,	AnsLoss=2.567636,	
2020-11-17 18:18:34,515 Epoch[4] Batch [16600]	Speed: 64.99 samples/s ETA: 0 d  0 h 32 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.014	Train-SoftAcc=0.745735,	AnsLoss=2.567559,	
2020-11-17 18:19:24,293 Epoch[4] Batch [16700]	Speed: 64.29 samples/s ETA: 0 d  0 h 32 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.407 O: 0.040 M: 0.013	Train-SoftAcc=0.745704,	AnsLoss=2.567733,	
2020-11-17 18:20:13,367 Epoch[4] Batch [16800]	Speed: 65.21 samples/s ETA: 0 d  0 h 30 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.401 O: 0.039 M: 0.014	Train-SoftAcc=0.745672,	AnsLoss=2.567638,	
2020-11-17 18:21:03,810 Epoch[4] Batch [16900]	Speed: 63.44 samples/s ETA: 0 d  0 h 30 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.414 O: 0.040 M: 0.014	Train-SoftAcc=0.745599,	AnsLoss=2.568353,	
2020-11-17 18:21:52,984 Epoch[4] Batch [17000]	Speed: 65.08 samples/s ETA: 0 d  0 h 29 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.401 O: 0.040 M: 0.013	Train-SoftAcc=0.745496,	AnsLoss=2.568778,	
2020-11-17 18:22:43,476 Epoch[4] Batch [17100]	Speed: 63.38 samples/s ETA: 0 d  0 h 29 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.414 O: 0.040 M: 0.014	Train-SoftAcc=0.745494,	AnsLoss=2.568752,	
2020-11-17 18:23:32,352 Epoch[4] Batch [17200]	Speed: 65.47 samples/s ETA: 0 d  0 h 27 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.399 O: 0.039 M: 0.014	Train-SoftAcc=0.745436,	AnsLoss=2.568944,	
2020-11-17 18:24:22,495 Epoch[4] Batch [17300]	Speed: 63.82 samples/s ETA: 0 d  0 h 27 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.410 O: 0.040 M: 0.014	Train-SoftAcc=0.745405,	AnsLoss=2.568964,	
2020-11-17 18:25:12,384 Epoch[4] Batch [17400]	Speed: 64.14 samples/s ETA: 0 d  0 h 26 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.014	Train-SoftAcc=0.745403,	AnsLoss=2.568750,	
2020-11-17 18:26:02,177 Epoch[4] Batch [17500]	Speed: 64.27 samples/s ETA: 0 d  0 h 25 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.407 O: 0.040 M: 0.014	Train-SoftAcc=0.745324,	AnsLoss=2.569271,	
2020-11-17 18:26:52,683 Epoch[4] Batch [17600]	Speed: 63.36 samples/s ETA: 0 d  0 h 24 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.414 O: 0.040 M: 0.013	Train-SoftAcc=0.745267,	AnsLoss=2.569464,	
2020-11-17 18:27:41,918 Epoch[4] Batch [17700]	Speed: 64.99 samples/s ETA: 0 d  0 h 23 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.014	Train-SoftAcc=0.745281,	AnsLoss=2.569360,	
2020-11-17 18:28:31,128 Epoch[4] Batch [17800]	Speed: 65.03 samples/s ETA: 0 d  0 h 22 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.014	Train-SoftAcc=0.745222,	AnsLoss=2.569387,	
2020-11-17 18:29:21,231 Epoch[4] Batch [17900]	Speed: 63.87 samples/s ETA: 0 d  0 h 22 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.411 O: 0.039 M: 0.014	Train-SoftAcc=0.745207,	AnsLoss=2.569351,	
2020-11-17 18:30:10,895 Epoch[4] Batch [18000]	Speed: 64.43 samples/s ETA: 0 d  0 h 21 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.406 O: 0.040 M: 0.013	Train-SoftAcc=0.745127,	AnsLoss=2.569642,	
2020-11-17 18:31:01,337 Epoch[4] Batch [18100]	Speed: 63.44 samples/s ETA: 0 d  0 h 20 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.415 O: 0.039 M: 0.014	Train-SoftAcc=0.745179,	AnsLoss=2.569164,	
2020-11-17 18:31:50,553 Epoch[4] Batch [18200]	Speed: 65.02 samples/s ETA: 0 d  0 h 19 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.014	Train-SoftAcc=0.745158,	AnsLoss=2.569453,	
2020-11-17 18:32:40,677 Epoch[4] Batch [18300]	Speed: 63.84 samples/s ETA: 0 d  0 h 18 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.410 O: 0.040 M: 0.013	Train-SoftAcc=0.745119,	AnsLoss=2.569518,	
2020-11-17 18:33:30,208 Epoch[4] Batch [18400]	Speed: 64.61 samples/s ETA: 0 d  0 h 17 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.014	Train-SoftAcc=0.745077,	AnsLoss=2.569624,	
2020-11-17 18:34:19,433 Epoch[4] Batch [18500]	Speed: 65.01 samples/s ETA: 0 d  0 h 16 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.040 M: 0.013	Train-SoftAcc=0.745100,	AnsLoss=2.570005,	
2020-11-17 18:35:09,237 Epoch[4] Batch [18600]	Speed: 64.28 samples/s ETA: 0 d  0 h 16 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.408 O: 0.040 M: 0.014	Train-SoftAcc=0.745122,	AnsLoss=2.569687,	
2020-11-17 18:35:59,353 Epoch[4] Batch [18700]	Speed: 63.85 samples/s ETA: 0 d  0 h 15 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.410 O: 0.040 M: 0.014	Train-SoftAcc=0.745031,	AnsLoss=2.570513,	
2020-11-17 18:36:48,878 Epoch[4] Batch [18800]	Speed: 64.62 samples/s ETA: 0 d  0 h 14 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.404 O: 0.040 M: 0.014	Train-SoftAcc=0.745017,	AnsLoss=2.570950,	
2020-11-17 18:37:38,499 Epoch[4] Batch [18900]	Speed: 64.49 samples/s ETA: 0 d  0 h 13 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.405 O: 0.040 M: 0.013	Train-SoftAcc=0.745013,	AnsLoss=2.571052,	
2020-11-17 18:38:27,684 Epoch[4] Batch [19000]	Speed: 65.06 samples/s ETA: 0 d  0 h 12 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.401 O: 0.040 M: 0.014	Train-SoftAcc=0.745014,	AnsLoss=2.571089,	
2020-11-17 18:39:17,312 Epoch[4] Batch [19100]	Speed: 64.48 samples/s ETA: 0 d  0 h 12 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.406 O: 0.039 M: 0.014	Train-SoftAcc=0.744948,	AnsLoss=2.571065,	
2020-11-17 18:40:07,275 Epoch[4] Batch [19200]	Speed: 64.05 samples/s ETA: 0 d  0 h 11 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.409 O: 0.039 M: 0.014	Train-SoftAcc=0.744845,	AnsLoss=2.571621,	
2020-11-17 18:40:56,490 Epoch[4] Batch [19300]	Speed: 65.02 samples/s ETA: 0 d  0 h 10 m	Data: 0.005 Tran: 0.004 F: 0.026 B: 0.402 O: 0.039 M: 0.014	Train-SoftAcc=0.744801,	AnsLoss=2.571604,	
2020-11-17 18:41:47,032 Epoch[4] Batch [19400]	Speed: 63.31 samples/s ETA: 0 d  0 h  9 m	Data: 0.005 Tran: 0.005 F: 0.026 B: 0.415 O: 0.039 M: 0.014	Train-SoftAcc=0.744739,	AnsLoss=2.572109,	
2020-11-17 18:42:36,125 Epoch[4] Batch [19500]	Speed: 65.18 samples/s ETA: 0 d  0 h  8 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.400 O: 0.040 M: 0.013	Train-SoftAcc=0.744734,	AnsLoss=2.572480,	
2020-11-17 18:43:25,773 Epoch[4] Batch [19600]	Speed: 64.45 samples/s ETA: 0 d  0 h  7 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.406 O: 0.040 M: 0.013	Train-SoftAcc=0.744718,	AnsLoss=2.572769,	
2020-11-17 18:44:15,016 Epoch[4] Batch [19700]	Speed: 64.99 samples/s ETA: 0 d  0 h  7 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.402 O: 0.039 M: 0.014	Train-SoftAcc=0.744705,	AnsLoss=2.572955,	
2020-11-17 18:45:05,119 Epoch[4] Batch [19800]	Speed: 63.87 samples/s ETA: 0 d  0 h  6 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.410 O: 0.040 M: 0.014	Train-SoftAcc=0.744740,	AnsLoss=2.573301,	
2020-11-17 18:45:54,559 Epoch[4] Batch [19900]	Speed: 64.73 samples/s ETA: 0 d  0 h  5 m	Data: 0.005 Tran: 0.004 F: 0.028 B: 0.403 O: 0.040 M: 0.014	Train-SoftAcc=0.744708,	AnsLoss=2.573456,	
2020-11-17 18:46:44,253 Epoch[4] Batch [20000]	Speed: 64.39 samples/s ETA: 0 d  0 h  4 m	Data: 0.005 Tran: 0.005 F: 0.028 B: 0.405 O: 0.040 M: 0.014	Train-SoftAcc=0.744656,	AnsLoss=2.574155,	
2020-11-17 18:47:33,825 Epoch[4] Batch [20100]	Speed: 64.55 samples/s ETA: 0 d  0 h  3 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.014	Train-SoftAcc=0.744570,	AnsLoss=2.574782,	
2020-11-17 18:48:23,368 Epoch[4] Batch [20200]	Speed: 64.59 samples/s ETA: 0 d  0 h  3 m	Data: 0.005 Tran: 0.004 F: 0.027 B: 0.405 O: 0.040 M: 0.014	Train-SoftAcc=0.744494,	AnsLoss=2.574830,	
2020-11-17 18:49:13,139 Epoch[4] Batch [20300]	Speed: 64.29 samples/s ETA: 0 d  0 h  2 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.407 O: 0.040 M: 0.014	Train-SoftAcc=0.744359,	AnsLoss=2.575259,	
2020-11-17 18:50:02,589 Epoch[4] Batch [20400]	Speed: 64.71 samples/s ETA: 0 d  0 h  1 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.404 O: 0.040 M: 0.014	Train-SoftAcc=0.744307,	AnsLoss=2.575646,	
2020-11-17 18:50:52,581 Epoch[4] Batch [20500]	Speed: 64.01 samples/s ETA: 0 d  0 h  0 m	Data: 0.005 Tran: 0.005 F: 0.027 B: 0.409 O: 0.040 M: 0.014	Train-SoftAcc=0.744282,	AnsLoss=2.575984,	
2020-11-17 19:08:21,382 New Best Val SoftAcc: 0.7524616718292236, Epoch: 4
2020-11-17 19:08:21,398 Epoch[4] 	Val-SoftAcc=0.752462,	
2020-11-17 19:08:21,398 Best Val SoftAcc: 0.7524616718292236, Epoch: 4
